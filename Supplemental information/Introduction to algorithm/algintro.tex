\documentclass{article}
%\documentclass[9pt]{extarticle}
%\usepackage[margin=1.5in]{geometry}
\usepackage[
backend=bibtex]{biblatex}
\usepackage{graphicx}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{BOONDOX-cal} % a calligraphic font that includes lowercase letters, will be used with mathcal command
\usepackage{babel, blindtext}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amssymb}
\newenvironment{nohyphen}
  {\tolerance=1% Also consider setting \pretolerance
   \emergencystretch=\maxdimen%
   \hyphenpenalty=10000%
   \hbadness=10000}% \begin{nohyphen}
  {\par}% \end{nohyphen}


\addbibresource{algintro.bib}

\begin{document}

\title{Introduction to the Linear \\ Programming Algorithm \\ in "Modeling Fee Shifting \\ With Computational Game Theory"}
\author{Michael Abramowicz \\ \href{mailto:abramowicz@law.gwu.edu}{abramowicz@law.gwu.edu} \\ George Washington University Law School}

\maketitle

This supplemental file provides an introduction to the algorithm used in the main paper. The algorithm is described in more detail in von Stengel, van den Elzen, and Talman (2002) \cite{vonstengelvandenelzentalman}.

Let the payoffs for players 1 and 2, respectively, be represented by the $M \times N$ matrices $A$ and $B$, whose entries are positive; any game with negative payoffs can be scaled to an equivalent such game. Player 1's strategy can thus be represented by a vector $x \in \mathbb{R}^M$ whose components sum to 1, and Player 2's strategy can be represented by a vector $y \in \mathbb{R}^N$ whose components have the same property. Using matrix notation, if $E=[1, ..., 1]\in\mathbb{R}^{1XM}$ and $F=[1, ..., 1]\in\mathbb{R}^{1XN}$, then $Ex=1$, $Fy=1$, and $x,y>0$.  Player 1's strategy is called a "best response" to a strategy $y$ if it maximizes the expected payoff $x^TAy$ subject to the $Ex=1$ constraint, and similarly a strategy $y$ maximizing $x^TBy$ subject to the $Fy=1$ constraint is a best response to $x$. The strategy pair $(x,y)$ forms a Nash equilibrium if each is a best response to the other. To find a Nash equilibrium, one can take advantage of a linear programming principle known as duality. Under strong duality, if there is an optimal solution to a "primal LP," then a dual LP has the same optimal solution. In the dual LP, the variables and constraints are reversed and the objective (maximization or minimization) is inverted, relative to the primal LP. Thus, the primal problem of maximizing $x^TAy$ subject to $Ex=e$ (where $e=1$) has a dual problem of finding $u$ that minimizes $e^Tu$ subject to $E^Tu-Ay \geq 0$. A similar dual minimization problem can be used to represent player 2's constrained maximization of $x^TBy$.

In von Stengel (2002), Theorem 2.4 shows that $(x,y)$ form a Nash equilibrium if and only if, for some $u$ and $v$, all of the following hold:

\begin{align*}
x^T(E^Tu-Ay) = 0 \\
y^T(F^Tv-B^Tx) = 0 \\
Ex = e \\
Fy = f\\
E^T u - A y \geq 0 \\
F^Tv - B^Tx \geq 0 \\
x, y \geq 0
\end{align*}

\noindent These conditions collectively define a mixed linear complementarity problem (LCP). The word "complementarity" refers to the fact that because $x$, $y$, $A$, and $B$ are nonnegative, the first line implies that $x$ and $E^Tu-Ay$ cannot have a positive component in the same position. The same holds for $y$ and $F^Tv-B^Tx$. The best known algorithm for finding a solution to a linear complementarity problem is that of Lemke and Howson (1964) \cite{lemkehowson}. 

Even this algorithm, which is beyond our scope here, is inadequate to the settlement bargaining problem. The problem is that the bimatrix game will be too large. When an extensive form game is converted to a matrix, the matrix must contain a separate row for all permutations of the choices that the row player may make at an information set, and similarly a column for each permutation of the column player's information set choices. In our game, for example, a plaintiff faces 20 different information sets (corresponding to the previous decision by the plaintiff of whether to quit the game if settlement fails and to 10 different liability signals), at each of which the plaintiff may choose 10 offer levels. Thus, that alone produces $10^{20}$ pure strategies for the plaintiff; adding the filing and quit decisions to the strategy makes for exponentially more rows. The total number of cells in the matrix is considerably larger than $10^{40}$. 

Several different scholars, the earliest being Romanovskii (1962) \cite{romanovskii}, offer a way around this dilemma. The trick, as explained by Koller, Megiddo, and von Stengel (1996) \cite{kollermegiddovonstengel}, is to craft a matrix in which the rows or columns represent not a player's pure strategies, but instead the sequences that the player may play. For example, in the litigation game, a sequence for the plaintiff is to file the suit, decide not to abandon if settlement fails, and then offer a settlement at the third available settlement level. Note that some sequences may be incompatible, because it may be impossible for a player to play a certain information set given a move by another; thus, the relevant matrix includes a zero in such cells. 

The von Stengel, van den Elzen, and Talman (2002) algorithm adapts the approach in Koller, Megiddo, and von Stengel (1992). It combines techniques used in von Stengel (1996) with developments in van den Elzen and Talman (1999), which adapts the Lemke-Howson algorithm to ensure perfect equilibria. The result is an algorithm that produces perfect, Nash equilibria. The requirement of perfection would not be needed if players committed to strategies at the outset of the game. But in litigation, such commitments do not occur. Thus, even if an equilibrium meets the Nash criterion, meaning that neither player will have an incentive at the outset of the game to change its strategy choice given the opponent's strategy choice, it may be imperfect, if a player might have an incentive to deviate in its strategy choice after learning new information. The solution concept of perfect Bayesian equilibrium, a term in use since at least the 1960s, has various formal definitions in the literature, including that of Fudenberg and Tirole (1991) \cite{fudenberg}, and is the imperfect information analogue of the subgame perfection equilibrium concept proposed by Selten (1965) \cite{selten}.

The algorithm is initialized by setting every information set to a fully mixed behavior strategy, that is a strategy in which each action has some positive probability of being played. Except where noted later, we chose to initialize each information set such that each action has an equal chance of being played. A data structure called a tableau is initialized in turn based on these values. This tableau encodes not only action probabilities, but also the relationships among information sets, specifically which information sets may follow other information sets in sequence. The initialization is designed so that the equations reflected by the tableau reflect a "basic feasible solution" to some of the equations in the linear complementarity problem, albeit ordinarily not a solution that corresponds to a perfect Nash equilibrium.  The algorithm then proceeds through a series of pivoting steps, which represent  linear algebraic manipulations in which variables are added to or removed from the list of non-zero variables known as the basis. When the variable initially added to the basis eventually leaves the basis, a Nash equilibrium is guaranteed.



\printbibliography
\end{document}
