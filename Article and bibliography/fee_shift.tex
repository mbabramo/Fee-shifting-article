\documentclass{article}
%\documentclass[9pt]{extarticle}
%\usepackage[margin=1.5in]{geometry}
\usepackage[
backend=bibtex]{biblatex}
\usepackage{graphicx}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{BOONDOX-cal} % a calligraphic font that includes lowercase letters, will be used with mathcal command
\usepackage{babel, blindtext}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amssymb}
\newenvironment{nohyphen}
  {\tolerance=1% Also consider setting \pretolerance
   \emergencystretch=\maxdimen%
   \hyphenpenalty=10000%
   \hbadness=10000}% \begin{nohyphen}
  {\par}% \end{nohyphen}
 
\addbibresource{fee_shift.bib}

\begin{document}

\title{Modeling Fee Shifting \\ With Computational Game Theory}
\author{Michael Abramowicz \\ \href{mailto:abramowicz@law.gwu.edu}{abramowicz@law.gwu.edu} \\ George Washington University Law School}

\maketitle

\begin{abstract}
\begin{nohyphen}
Previous computational models of settlement bargaining in litigation have lacked game theoretic foundations. Modern mathematical models, by contrast, generally seek to identify perfect Bayesian Nash equilibria. Algorithmic game theory, however, can be used to compute such equilibria, and this article uses one tool of algorithmic game theory to illustrate how computation and mathematics can serve as complements in modeling settlement bargaining, with each addressing the limitations of the other. It does so by building on a cutting-edge model of settlement bargaining, Dari-Mattiacci and Saraceno (2020), which incorporates both two-sided asymmetric information and fee-shifting. The algorithm, introduced in von Stengel et al. (2002), applies linear programming techniques to the sequence form of the extensive-form game tree, and it computes exact perfect Bayesian Nash equilibria. The algorithm can be applied to optimize among piecewise linear strategies but also can relax the piecewise linearity assumption for a discretized version of the game, with each player receiving one from a finite set of signals and choosing one from a finite set of offers.  This makes it straightforward to alter some assumptions in Dari-Mattiacci and Saraceno's model, including that the evidence about which the parties receive signals is irrelevant to the merits and that the party with a stronger case on the merits also has better information. The computational model can also toggle easily to explore cases involving liability rather than damages and can incorporate risk aversion. A significant drawback of the computational model is that bargaining games may have many equilibria, making it difficult to assess whether changes in equilibria associated with parameter variations are causal.
\end{nohyphen}
\end{abstract}

\section{Introduction}
The literature analyzing the effects of fee shifting confronts a daunting analytic challenge. Settlement bargaining is a two-player asymmetric information game. The gold standard solution to such a game is a pair of common knowledge strategies that form a perfect Bayesian equilibrium. The perfection requirement, as defined by Fudenberg and Tirole (1991) \cite{fudenberg}, specializes the general Nash \cite{nash} equilibrium criterion in an imperfect information game, by insisting that at no point in the game may a player have any incentive to change the player's strategy. Each player applies Bayesian reasoning to incorporate new information, such as signals of case quality, into estimates of trial outcomes, and the player's probabilistic beliefs are required to be correct given such information. Complicating the challenge of crafting such equilibria, each party might decide not to contest the litigation, one or both parties may be risk averse, players may have asymmetric information, a case may concern liability or damages, and the loser may or may not be required to pay the winner's fees.

Incorporating anywhere near all of these considerations into a single model of settlement bargaining has proven elusive. The settlement bargaining modeler stands before a smorgasbord of potentially critical game features, but faces the admonition to choose no more than a few. The result, Daughety and Reinganum (1993) \cite{daughetyreinganum1993} observed, is a literature that "has grown in a disorganized fashion, resulting in a multitude of models involving different informational endowments and timing structures." This statement remains true nearly three decades later, with the  settlement-bargaining-modeling art making unmistakable but limited progress. The earliest models of Landes (1971) \cite{landes}, Posner (1973) \cite{posner}, and Gould (1973) \cite{gould} had ignored the challenges of Bayesian inference. Later came models, such as Bebchuk (1984) \cite{bebchuk84} and Polinsky and Rubinfeld (1998) \cite{polinskyrubinfeld}, in which one party knows the probability of liability or the amount of damages while the other party knows only the distribution, and Daughety and Reinganum (1994) \cite{daughetyreinganum1994}, in which one party has information on liability and the other party, on damages. The latest generation of scholarship, including Friedman and Wittman (2006) \cite{friedmanwittman}, Klerman, Lee, and Liu (2018) \cite{klermanleeliu}, and Dari-Mattiacci and Saraceno (2020) \cite{darimatiaccisaraceno}, models two-sided asymmetric information, in which each of the plaintiff and defendant has independent private information about the same issue, for example about the level of damages. The last of these even succeeds at the Herculean task of incorporating fee shifting, but we will see that even it does not escape the curse of dimensionality, adopting a number of restrictive assumptions that make it difficult to assess the generality of its conclusions.

The literature is extraordinarily clever, in both the positive and negative senses of the word. It takes advantage of mathematical assumptions to make otherwise intractable problems tractable. We can expect further progress from relaxing different assumptions, but the goal of developing a single mathematical model that allows exploration of different values of a large number of variables may be unattainable. The literature develops critical intuitions about settlement bargaining, including how changing fee shifting rules may augment or diminish the effectiveness of the litigation system, and review articles, like Katz and Sanchirico (2012) \cite{katzsanchirico}, informally integrate various models' conclusions about how fee shifting might affect trial rates or settlement rates with different structures to the litigation game. Even with such reviews, however, it is difficult to generalize about the wisdom of fee shifting, because of the interactivity between trial and settlement rates. If, for example, increased ease of settlement leads to plaintiffs' bringing and defendants' defending more cases, total litigation expenditures in principle could rise. 

Scholars have studied settlement bargaining with other methodologies, but these have their own limitations. Empirical analyses are limited to studying the rare cases in which a change in fee-shifting rules occurs, as in the examination by Hughes and Snyder (1995) \cite{hughessnyder} of a briefly-lived policy experiment in Florida. Laboratory experiments offer another approach, with contributions by Coursey and Stanley (1988) \cite{courseystanley}, Inglis et al. (2005) \cite{inglisetal},  Rowe and Vidmar (1988) \cite{rowevidmar}, and Main and Park (2000) \cite{mainpark}. It is not clear, however, whether modest stakes produce results similar to those of real litigation. A final methodology in the literature is computer-based simulation. Priest and Klein (1984) \cite{priestklein}, Katz (1987) \cite{katz}, Hause (1989) \cite{hause}, and Hylton (1993) \cite{hylton}, were pioneers in using computation, either independently or as complements to formal models. While these articles all include innovations building on the Landes-Gould-Posner model, they share a significant limitation: Unlike the math models, the simulations do not seek perfect Nash equilibria.

It is, however, possible to harness computational power in the quest for perfect Bayesian equilibria, by turning to computational game theory. The settlement bargaining literature has acknowledged the importance of game theoretic concepts, but articles build at most relatively small game trees. Acknowledging that litigation can be viewed as "a particular extensive-form bargaining game," Spier (1994, pp. 202-03) \cite{spier} sensibly worries that the results would be sensitive to issues such as "the structure of the asymmetric information." This concern suggests that solvable game theoretic models are insufficiently rich to encapsulate critical aspects of the litigation game. Computational game theory, however, allows for the identification of equilibria in games that could not practically be solved by hand. A subliterature focuses directly on the solution of two-player (and sometimes $n$-player) general sum games. A litigation game between plaintiff and defendant is general sum, which can be more difficult than a zero-sum game to solve, because the players may transfer wealth not only from defendant to plaintiff, but also from both litigants to lawyers. A useful review of algorithms that can help solve such games is von Stengel (2002) \cite{vonstengel2002}.

A publicly available open source software package known as Gambit by McKelvey et al. (2016) \cite{mckelvey} features a number of these algorithms. This article, however, applies an algorithm not included in Gambit, specifically an algorithm described in an article in \textit{Econometrica}: von Stengel, van den Elzen, and Talman (2002) \cite{vonstengelvandenelzentalman}. This algorithm, described further below, is guaranteed to produce perfect Bayesian Nash equilibria in a finite game in which the players have perfect recall. Sometimes, these equilibria are pure, with players acting deterministically conditional on the information that they possess, but at other times, they are mixed, with the players randomly choosing at certain moments of the game between or among equally good strategies, each with some nonzero probability. Mixed strategies need not reflect explicit randomization by players; they may be understood as describing balanced populations of litigants who take different approaches, none better than others given opponents' strategies, for reasons exogenous to the model. The authors test their algorithm on games of up to 1,023 nodes. This article pushes the computational limits of the algorithm, applying it to each of a large number of games with up to 16,111 nodes. By separately identifying equilibria corresponding to different information and game structures, we can assess the conditions in which changing fee-shifting rules may increase or decrease the effectiveness of the litigation system, as manifested in accuracy or trial rates, assuming the litigation game is played in equilibrium by rational actors. This approach thus enables modeling of a richer and more diverse litigation environment than any single prior approach.

To illustrate how this approach can complement analytic models, this Article focuses on the model of Dari-Mattiacci and Saraceno (2020), the first article to integrate both two-sided asymmetric information and fee-shifting. In this model, both players know the true quality of the litigation, but the judgment depends not only on this value, but also on the sum of signals independently received by the parties. 

Part 1 describes both the game trees to which the algorithm will be applied and the algorithm itself, and it reports statistics on how the size of the game tree affects the running time of the algorithm. Part 2 provides the central results. It begins by scrutinizing the results of two simulations, one in which the American rule applies and one in which the British rule applies, where all other variables are set to baseline values (admittedly values not calibrated to any particular real-world values). This provides some tentative findings, but explores a tiny proportion of the variable space. It then illustrates how a range of values for fee-shifting multipliers and the cost of litigation affect case dispositions (including filing and answer decisions, settlements, and decisions to quit after settlement failure), which in turn affect litigation accuracy and total expenditure levels. Then, the article deviates from baseline parameter values for other variables, demonstrating how changing risk preferences, information endowments, costs structure, and other aspects of game structure may affect outcomes, while continuing to vary cost and fee-shifting levels. Part 3 provides robustness tests of the principal results by considering a much larger number of equilibria identified for a smaller version of the game tree. This permits assessment both of whether the results are sensitive to the granularity of the game tree and whether it matters whether the players play an individual equilibrium, a correlated equilibrium (i.e., when one player plays a particular equilibrium, the other player plays its corresponding strategy) or an average equilibrium (i.e., where one player might be playing one equilibrium while its opponent plays another). Part 4 provides some conclusions and explains why they differ from earlier findings in the literature.

\section{Analytical Models of Two-Sided Asymmetric Information}

Because this article's goal is to illustrate how computational models can build on limitations of an analytical model, and vice-versa, we will focus on the structure and methodological choices in Dari-Mattiacci and Saraceno (2020). We begin by reviewing the Friedman and Wittman (2006) \cite{friedmanwittman} upon with Dari-Mattiacci and Saraceno build, before summarizing the Dari-Mattiacci and Saraceno model and exploring some of the assumptions inherent in the article.

\subsection{Friedman and Wittman's Averaged Signals Model}

In the one-sided information models, the structure of bargaining often affects which party receives most of the surplus. Friedman and Wittman avoid this problem by adopting the bargaining protocol of Chatterjee and Samuelson (1983) \cite{chatterjeesamuelson}. In Chaterjee-Samuelson bargaining, the plaintiff and defendant simultaneously submit offers. If the plaintiff's exceeds the defendant's, the case definitively settles at the midpoint; otherwise, bargaining has failed. Costs of trial are borne only in the event of bargaining failure.  Friedman and Wittman justify this bargaining structure not on the ground that the protocol is commonly used (it is not), but on the ground that it provides a useful reduced form of a more complicated bargaining process.  In contrast to divergent expectations models, with Chaterjee-Samuelson bargaining, a case may go to trial even though there is a social surplus from settlement given the parties' expectations. The reason is that the parties may shade their offers in the hope of deriving a larger portion of the settlement surplus, even at the risk of bargaining failure.

The informational structure is arrestingly simple. The plaintiff observes a signal $\theta_p$ drawn from a known distribution, and the defendant independently observes a signal $\theta_d$ drawn from the same distribution. The principal results of the paper apply to a "basic litigation model" in which the distribution is the uniform distribution; this extends without loss of generality to any uniform distribution between a lower bound of $L$ and an upper bound of $U$. In the event that settlement fails, a judgment is entered in the amount of the average $(\theta_p + \theta_d)/2$. Perhaps one can imagine situations in which this might be realistic. For example, the parties might have information about different components of damages in a case in which liability is uncontested, and should trial ensue, the information will be revealed and the judgment will be the sum. But a more intuitively appealing model in most situations would reverse the causality. Signals would depend on the underlying truth to be revealed at judgment, rather than the judgment dependingon signals. Friedman and Wittman cleverly recognize, however, that modeling litigation in this way makes the model tractable.

Friedman and Wittman derive a Nash equilibrium in the basic litigation game. In this equilibrium, the plaintiff will ordinarily offer $\frac{2}{3}\theta_p -2c + \frac{1}{2}$, and the defendant will ordinarily offer $\frac{2}{3}\theta_d + 2c - \frac{1}{6}$, where $c$ represents each party's trial cost.  The word "ordinarily" signals what may seem a mild caveat: Neither party will ever make an offer beyond the range of the other party's possible offers. Thus, the plaintiff's offers are truncated above at $\min(1, 2c + \frac{1}{2})$ and below at $\max(0, 2c - \frac{1}{6})$, while the defendant's offers are truncated above at $\min(1, \frac{7}{6} - 2c)$ and below at $\max(0, -2c + \frac{1}{2})$. Friedman and Wittman do not eliminate the possibility that there might be some nonlinear Nash equilibrium, but they prove that the equilibrium they derive is the unique nontrivial piecewise linear equilibrium. There are also infinitely many trivial equilibria, in which the plaintiff's settlement demands always exceed the defendant's. 

Friedman and Wittman's model permits them to focus on the trial rate. They derive a piecewise quadratic formula for the trial rate, and they also examine, in the tradition of Priest-Klein, how the trial rate varies near the midpoint of the decision spectrum. They show that when trial costs are sufficiently low ($c < \frac{1}{6}$), the probability of a trial is higher, the farther the judgment would be from $\frac{1}{2}$, and when trial costs exceed this threshold, the probability of a trial is highest at the $\frac{1}{2}$ point. The intuition is that when costs are high, the parties become more generous, and so the plaintiff's range of offers will fall below the defendant's. The truncations then ensure that cases at the extremes, where either both parties receive a low signal or both parties receive a high signal, are more likely to settle. When trial costs are low, the parties are less generous, and the plaintiff's range of offers will be above the defendant's. Cases at the extremes are then less likely to settle. With the basic litigation game, the $\frac{1}{6}$ cost threshold occurs where the parties' range of offers are equal. Friedman and Wittman also offer a graphical argument that extends to other continuous distributions, though they do not expressly consider the case where liability rather than damages is uncertain.

\subsection{Dari-Mattiacci and Saraceno's \\ Evidentiary Signals Model}

Dari-Mattiacci and Saraceno (2020) illustrate the challenge of building on Friedman and Wittman by successfully extending the model to fee shifting. The article includes an online appendix with 60 pages of proofs. The difficulty stems from the need to address four principal cases, depending on relative values of parameters, and within these principal cases, to make various calculations that depend on the relative values of other parameters, including in many instances five different formulas for five different ranges of a variable. The resulting product is testimony both to human ingenuity and to endurance, and it makes breakthroughs in our understanding of the effects of fee-shifting with two-sided asymmetric information.

As in Friedman and Wittman, plaintiff and defendant receive signals, now denoted $\theta_\Pi$ and $\theta_\Delta$, respectively, and the judgment is an average of the signals. Now, however, both parties have common knowledge of the true merits of the litigation, denoted by $q$. The signals thus do not serve the function of informing the parties of the true merits, but rather of providing the parties with evidence that they may use to convince the court. The plaintiff's signal $\theta_\Pi$ is drawn from a uniform distribution on the interval $(0,q)$, and the defendant's signal, on the interval $(q,1)$. Because the defendant's signal can be no less than $q$, the plaintiff's best possible evidence, where $\theta_\Pi = q$, would convince the court that the judgment must be at least $q$. Similarly, the defendant's best possible evidence, where $\theta_\Delta = q$, would convince the court that the judgment must be no more than $q$. But the litigants do not always draw the best possible evidence.

The fee shifting rule that Dari-Mattiacci and Saraceno primarily analyze is triggered based on (1) whether the final judgment is above or below $\frac{1}{2}$ (i.e., which party "wins" in the sense of being awarded more than half of the contested damages), and (2) whether the evidence of the winning party is sufficiently strong. If the judgment is less than $\frac{1}{2}$, then the defendant might be able to shift its costs to the plaintiff, but only if the defendant's signal falls below some threshold, i.e. $\theta_\Delta < t$, where $0 \leq t \leq 1$. Likewise, if the judgment is greater than $\frac{1}{2}$, then the plaintiff might be able to shift its costs to the defendant, but only if the plaintiff's signal exceeds a threshold, i.e. $\theta_\Pi > 1 - t$. An intuition is that if a party wins a case merely because its opponent has produced little evidence, a court will not order fee-shifting; another is that a court will only order shifting of fees when those fees were spent on producing strong evidence. Note that when $t = 0$, fees will never be shifted, so this extreme is the American rule of no fee shifting, and when $t = 1$, fees will always be shifted to a winning party (i.e., to the plaintiff if the final judgment exceeds $\frac{1}{2}$ and to the defendant if the final judgment is less than $\frac{1}{2}$), so that extreme is the English rule of universal fee shifting. The analysis thus effectively allows for a continuum of fee shifting rules.

This information structure enables Dari-Mattiacci and Saraceno to derive the offers that the parties will make. They prove that each party's offer function is a best response to its opponent's offer function and thus that a Bayesian Nash equilibrium exists. They also derive formulas for settlement amounts, along with identification of the ranges of parameters values where such settlements occur, and accordingly of the litigation rate. They prove that the litigation rate depends only on $c$ (now representing the combined trial cost of the two parties) and is thus independent of both case quality $q$ and the fee-shifting rule $t$. This produces the surprising conclusion that the litigation rate is the same under both the American and the English rule. Finally, they offer a calculation of litigation accuracy, and they prove that when costs are below a certain threshold, the English rule produces more accuracy than the American rule, while the reverse is true when costs are above a certain threshold. The stylized fact that litigation is cheaper in England may thus help explain the choice of rule in each country.

\subsection{Assumptions in Dari-Mattiacci and Saraceno's Model}

The Dari-Mattiacci and Saraceno model adopts a number of assumptions. Many of these assumptions appear to be driven, quite reasonably, by the demands of mathematical tractability, and it is difficult to develop strong intuitions for whether they matter. In identifying these assumptions, we create a series of challenges for a computational model that aspires to assess the robustness of the analytical model.

\paragraph{Structural constraints}
\subparagraph{Piecewise linearity} Dari-Mattiacci and Saraceno explicitly assume a linear relationship between the parties' signals and their offers. They allow, however, for discontinuities in the linear relationship. In this sense, the strategies they model are similar to those of Friedman and Wittman, and indeed Dari-Mattiacci and Saraceno similarly truncate the parties' strategies. The assumption is somewhat stronger, however, in that Friedman and Wittman demonstrated that the piecewise linear strategies they derived would be a Nash equilibrium even when nonlinear strategies are possible. On the other hand, Dari-Mattiacci and Saraceno allow for additional discontinuities at points where fee-shifting would change. This is central to the design of their model and the thrust of their analysis. Because fee-shifting depends partly on the quality of the evidence possessed by the winning party, a litigant will know whether it will be entitled to fee-shifting if it wins, and the signal values at which this fact changes are points at which Dari-Mattiacci and Saraceno are able to break the problem down into smaller pieces. Piecewise linearity thus allows for explicit modeling of the effects of changes in a fee-shifting rule, but because it is unclear how restrictive this assumption is, it is a prime candidate for relaxation in a computational model.
\subparagraph{Asymmetric information quality equivalence} Recall that the plaintiff receives a signal in the range $(0,q)$ and the defendant, in $(q,1)$. As a consequence, when $q > \frac{1}{2}$, the plaintiff's signal has a greater potential effect than the defendant's, and when $q < \frac{1}{2}$, the reverse is true. The single variable $q$ thus serves two, independent functions in the model: one is to represent the "true merits" of the case, while the other is to represent the degree of information asymmetry. This greatly increases the tractability of the model, and plausibly it allows for consideration of both issues related to accuracy and issues related to information asymmetry. The problem, though, is that the issues are necessarily conflated; where a case is at an extreme of the probability distribution, there is always high information asymmetry. There is no particular reason to believe that true merits should generally track information asymmetry in this way. The question thus arises whether the results would be the same if the model allowed independent variation of true merits and information asymmetry. 

\paragraph{Parameter values}
\subparagraph{Balanced asymmetric information}Meanwhile, the true merits variable is constrained so that $\frac{1}{3} \leq q \leq \frac{2}{3}$. The reason for this constraint is that with more extreme values of $q$, the increasingly one-sided nature of asymmetric information leads the pure strategy equilibria derived by the authors to break down. This highlights once again the problematic nature of asymmetric information quality equivalence, because it means that the authors not only cannot model situations with relatively high information asymmetry, but also that they cannot model situations in which the true merits of a case are near the extremes of the probability distribution. Perhaps a computational model might be able to find an equilibrium with relatively extreme quality values and/or with relatively extreme information asymmetry, and this could help extend the understandings provided by the model.

\subparagraph{Low or moderate cost}Dari-Mattiacci and Saraceno follow Friedman and Wittman in implicitly assuming that the cost variable is not so high that the plaintiff's untruncated offer range is entirely below the defendant's untruncated offer range. The truncation functions defined by Friedman and Wittman are undefined, because when their $c$ is sufficiently high, they instruct that the plaintiff's offers should be truncated above at 1 and below at a number greater than 1, and similarly the defendant's offers are truncated below at 0 and above at a number less than 1. With sufficiently high costs, there will be many Nash equilibria; the parties will be determined not to go to trial, but neither party would deviate from any positive allocation of the surplus from settlement. Literal application of the Dari-Mattiacci and Saraceno formula, however, would lead to both players truncating their bids and would not choose any of these equilibria.

In a subtle way, the Dari-Mattiacci and Saraceno cost assumption is more restrictive than Friedman and Wittman's. As we will see shortly, a computational model can be used to assess whether parties' strategies form an equilibrium, and with sufficiently high costs, the bid functions identified by Dari-Mattiacci and Saraceno in some cases do not form equilibria. This can be traced, at least in part, to a complication in what Dari-Mattiacci and Saraceno call Case 4B. They implicitly assume that the bid functions that they derive would each contain a discontinuity, but if $6c(1-q) > 1$, the plaintiff's bid function consists only of a single line segment. It can be shown, for example, that for the parameters $t = 0.8, q = 0.4, c = 0.3$, the plaintiff's strategy cannot be a best response, because, given the defendant's presumed strategy, the plaintiff would be very slightly better off with a bid function in which it always bids one-third of its normalized signal. In correspondence, Dari-Mattiacci and Saraceno have acknowledged this complication and that their model implicitly assumes that $c$ is not too high. This is a reasonable assumption, but a challenge for the computational model is to overcome it.

\subparagraph{Risk neutrality}The plaintiff and defendant are assumed to be risk neutral. Incorporating risk aversion into the model would likely add considerable challenge, though the argument could still proceed in case-by-case fashion. Incorporating risk aversion is virtually costless to a computational model, requiring only the transformation of the parties' utilities in any game outcome. 

\paragraph{Game structure}

\subparagraph{Fee-shifting structure}Fee shifting in Dari-Mattiacci and Saraceno's model depends not only on which party wins more than half of the judgment at trial, but also on the quality of the evidence produced by the winning party. This is mathematically convenient, because each party knows the quality of its own evidence and thus whether fee-shifting will occur for any given value of the opponent's signal and any value of $t$. An alternative approach, however, would be for fee-shifting to depend on both parties' evidence. Indeed, Dari-Mattiacci and Saraceno explicitly consider fee-shifting based on the margin of victory, defined by a parameter $m$, where $0 \leq m \leq 1$. With this approach, if $\theta_\Pi + \theta_\Delta < m$, then the plaintiff must pay the defendant's fees, and if $\theta_\Pi + \theta_\Delta > 2 - m$, then the defendant must pay the plaintiff's fees. In this regime, if $m = 0$, no fee shifting occurs (the American rule), and if $m = 1$, fee shifting always occurs absent an evenly split judgment (the English rule); thus, the margin-of-victory approach converges with the other approaches at the extremes. Dari-Mattiacci and Saraceno explicitly calculate the parties' offers under this approach, but they do not prove their results related to accuracy. This raises the question whether their accuracy results are robust to the alternative specification. One might also imagine other fee-shifting rules, such as a simple rule in which a party always occurs when the party wins half of the judgment but the proportion of fees shifted may vary from 0 to 1.

\subparagraph{Damages vs. liability}Dari-Mattiacci and Saraceno explicitly describe their model as one in which the parties are arguing about how to divide a disputed asset, such as in a case of divorce, and they point out that without loss of generality, this can be extended to a judicial determination of damages between some minimum and maximum value. An extension would be to consider cases where liability is at issue, i.e. where the plaintiff will receive 1 if $\theta_\Pi + \theta_\Delta > 1$ and 0 otherwise. For example, they might generalize the model to an arbitrary cumulative distribution function mapping $\theta_\Pi + \theta_\Delta$ onto the judgment, but this would add considerable challenge. Once again, this should be trivial in a computational model, which need only transform the judgment values in particular cases, either to 0 or 1 or based on some other distribution.   

\subparagraph{Signal variance independent of true merits}Dari-Mattiacci and Saraceno refer to the signals that the parties receive as "evidence" of the true merits of the case, but there is a paradox: The parties are assumed to know the true merits of the case ($q$) and indeed use this information in constructing their offer functions. Thus the variance in the signals that each party may receive has nothing to do with the merits. Given the fixed value of $q$, whether the plaintiff receives a signal slightly above 0 or slightly below $q$ tells the plaintiff nothing about the true merits. What receipt of the signal accomplishes is to inform the plaintiff about the plaintiff's likely ability to persuade the judge about the true merits. The judge does not know the true merits, but is trying to guess the true merits. The higher $q$, the higher the parties' signals will tend to be, so the judge's strategy is reasonable, even if non-Bayesian. But the result is that from the perspective of the parties, for whom $q$ is fixed, the randomness in case outcomes has to do only with who is lucky in finding promising evidence.

This point can be more clearly seen in a transformation of the model that Dari-Mattiacci and Saraceno offer. They note that the signals $\theta_\Pi$ and $\theta_\Delta$ can be mapped one-to-one onto signals from 0 to 1, which they label $z_\Pi$ and $z_\Delta$. These signals are thus independent signals from a unit uniform distribution, and the $\theta$ signals can be derived from them according to the formulas $\theta_\Pi = qz_\Pi$ and $\theta_\Delta=q+(1-q)z_\Delta$. This highlights that the $\theta$ signals result from commingling the true merits of the case and the random uniform distribution draws. With these transformations, the judgment depends on the following formula:

\begin{equation}
J(z_\Pi, z_\Delta) = \frac{1}{2}q + \frac{1}{2} (qz_\Pi+(1-q)z_\Delta)
\end{equation}

As this presentation makes clear, the decision is half based on the true merits of the case, independent of any evidence presented by the parties. Meanwhile, the decision is half based on a weighted average of the parties' uniform distribution draws, with the weights equal to $q$. Recall that $q$ represents the degree of information asymmetry. Thus, in effect, half of the judge's decision is based on the true merits and half of the judge's decision depends on a weighted average of signals that are entirely independent of the true merits. The only reason that this makes sense from the perspective of the judge is that the judge does not observe $z_\Pi$ and $z_\Delta$ directly. The Dari-Mattiacci and Saraceno model could be realistic in some contexts, in which the parties have asymmetric information about their persuasive abilities, independent of the merits. In any event, their approach may be necessary in a mathematical model that seeks, as theirs does, to measure accuracy. It is considerably easier (though still extraordinarily difficult) to measure outcomes relative to the constant $q$ than it would be relative to a function of $q$ and the parties signals. 

A challenge for the computational model is to assess whether results about accuracy continue to obtain when the true merits are defined to be inclusive of the parties' normalized signals. On this formulation, $q$ would represent knowledge that the parties share about the true merits, and the $z$ signals represent private information about the true merits. When the judge adds these together according to the above formula, the judge obtains not only the judgment, but also the true merits. This is thus a conceptual reformulation with no implications for which cases settle. It requires only an alteration of the definition of accuracy.

\paragraph{Accuracy definition}Dari-Mattiacci and Saraceno define inaccuracy in their appendix as "the square distance between the expected outcome $E_t$ and the merits $q$." We have already explored how we might reconceive the definition of the merits, so let us continue moving from right to left in this definition. 

The definition of $E_t$ is complex, involving double integrals over both costs and the parties' signals. The essence is that it is a measure of the expected outcome of a dispute, taking into account both the settlements and the trials. The outcome in the event of trial that they calculate is represented by $G$, which "captures both the decision on the merits and fee shifting." For example, if the judgment is for 0.45 and the plaintiff pays costs of 0.10 to the defendant, then $G=0.35$. The inclusion of fee shifting costs reflects that imposition of fee shifting not only affects settlement negotiations, but also affects the amount that the plaintiff must pay to the defendant at trial. It is reasonable to view the difference between the expected value of $G$ and the value of $q$ as a measure of accuracy, but the question remains whether conclusions about accuracy would be robust to alternative specifications.

\subparagraph{Outcome expectation}The specification chosen focuses on the expectation of settlement or trial results, rather than on the actual result in particular cases. It is a comparison of the expectation of the result with the true merits, not a measure of the error. If, for example, there are two scenarios in which the correct result based on the true merits would be for the defendant to pay the plaintiff 0.50, and in one scenario the defendant pays 0 and in the other scenario the defendant pays 1, then this measure would count the legal system as perfectly accurate. Because the parties are risk-neutral, they would be indifferent between receiving perfectly accurate results and results that are correct on average. 

An alternative measure, which arguably would be more appropriate at least for risk-averse parties, would aggregate the distance between the actual outcome and the ideal outcome in each case. In more technical terms, instead of calculating a measure of inaccuracy that is a function of $E_t$, the authors might have calculated a measure of expected inaccuracy in which the inaccuracy is calculated within each case rather than based on an average across cases. Easier said than done, of course. In the analytical model, this would require moving a minus $q$ term and a squared term within the double integrals in the current $E_t$ definition. 

\subparagraph{Accounting for costs}The accuracy measure also ignores the pre-fee shifting costs that the parties pay. Dari-Mattiacci and Saraceno note "that the plaintiff receives $G - \frac{c}{2}$ and the defendant pays $G + \frac{c}{2}$." Imagine a case with very high costs and no fee shifting, where each party spends a million dollars and the court arrives at precisely the correct conclusion that the defendant owes the plaintiff 50 cents. From this definition's perspective, this outcome counts as a perfectly accurate result. That is a plausible definition of accuracy, but one that offers no comfort to the parties. An alternative definition of accuracy would consider any amounts actually spent at trial, for example counting the outcome from the plaintiff's perspective as $G - \frac{c}{2}$. A similar definition could measure accuracy from the defendant's perspective. Either of these two approaches captures three distinct aspects of costs: (1) the costs impact settlement negotiations; (2) when trial occurs, the costs are deadweight losses to society at large; and (3) costs may reduce (or perhaps in some cases increase) the accuracy of adjudication viewed as a black box from the perspective of each individual litigant. Although it is reasonable for Dari-Mattiacci and Saraceno to define accuracy entirely independently of cost, an interesting question is whether any conclusions based on this definition will extend to definitions that incorporate costs.

\subparagraph{Squared vs. absolute value}Finally, one might quibble about the use of a squared term rather than an absolute value. Of course, it is conventional to measure (in)accuracy using the $\ell_2$ norm rather than the $\ell_1$ norm. The convention reflects the dominance of ordinary least squares regression over least absolute deviation regression, but that dominance stems as least in part from the greater tractability of the former. Portnoy and Koenker (1997) \cite{portnoykoenker} note that computational power mitigates this advantage, and that an advantage of the $\ell_1$ norm is that it is more robust to outliers. Because the Dari-Mattiacci and Saraceno definition compares the outcome expectation with $q$, any results on accuracy necessarily extend to the $\ell_1$ norm. The computational results here will be reported using the $\ell_1$ norm, because interpretation is more intuitive and because this will make it more straightforward to compare different accuracy measures.


\section{Litigation as an Extensive Form Game}

This section describes an algorithm that can be used to find equilibria in any extensive form game. It illustrates that this approach can come close to replicating the Friedman and Wittman results by applying the algorithm to a model in which each party selects a slope for its bid function and a truncation. It then explains how discretization can relax the assumption of piecewise linearity and thus allow for more complex bid functions. 

\subsection{The von Stengel, van den Elzen, and Talman Algorithm}

In principle, any two-player extensive form game can be presented in strategic form, with the parties' payoffs embedded in a matrix. The row player may use a pure strategy and select a single row from the matrix or a mixed strategy, a probability distribution over the matrix rows. The column player analogously chooses a column or a probability distribution over matrix columns. Nash (1951) famously proved that every strategic game involving a finite number of players has at least one equilibrium, now called a Nash equilibrium, in which neither player could increase the player's payoff by switching to a different strategy given the opponent's strategy. Moreover, given a game in strategic form, any equilibrium in pure strategies can be identified relatively easily by the algorithm of iterative elimination of dominated strategies. If a cell of the matrix exists where the column player's utility is greater than in any other cell in its row and the row player's utility is greater than in any other cell in its column, then that cell represents a Nash equilibrium. 

This approach is insufficient to find mixed strategy equilibria. The problem of finding Nash equilibria, however, can be converted into a linear programming problem. The reader with a strong interest in the algorithm applied here should read von Stengel (2002) for a comprehensive overview, including proofs that it produces equilibria. The reader interested solely in legal ramifications may skip this section altogether. A virtue of using computational game theory to identify equilibria is that one may choose to treat algorithms as black boxes, particularly because all equilibria found in this article were computationally verified.

Still, we will provide an introduction to the algorithm for the reader with an intermediate level of interest. Let the payoffs for players 1 and 2, respectively, be represented by the $M \times N$ matrices $A$ and $B$, whose entries are positive; any game with negative payoffs can be scaled to an equivalent such game. Player 1's strategy can thus be represented by a vector $x \in \mathbb{R}^M$ whose components sum to 1, and Player 2's strategy can be represented by a vector $y \in \mathbb{R}^N$ whose components have the same property. Using matrix notation, if $E=[1, ..., 1]\in\mathbb{R}^{1XM}$ and $F=[1, ..., 1]\in\mathbb{R}^{1XN}$, then $Ex=1$, $Fy=1$, and $x,y>0$.  Player 1's strategy is called a "best response" to a strategy $y$ if it maximizes the expected payoff $x^TAy$ subject to the $Ex=1$ constraint, and similarly a strategy $y$ maximizing $x^TBy$ subject to the $Fy=1$ constraint is a best response to $x$. The strategy pair $(x,y)$ forms a Nash equilibrium if each is a best response to the other. To find a Nash equilibrium, one can take advantage of a linear programming principle known as duality. Under strong duality, if there is an optimal solution to a "primal LP," then a dual LP has the same optimal solution. In the dual LP, the variables and constraints are reversed and the objective (maximization or minimization) is inverted, relative to the primal LP. Thus, the primal problem of maximizing $x^TAy$ subject to $Ex=e$ (where $e=1$) has a dual problem of finding $u$ that minimizes $e^Tu$ subject to $E^Tu-Ay \geq 0$. A similar dual minimization problem can be used to represent player 2's constrained maximization of $x^TBy$.

In von Stengel (2002), Theorem 2.4 shows that $(x,y)$ form a Nash equilibrium if and only if, for some $u$ and $v$, all of the following hold:

\begin{align*}
x^T(E^Tu-Ay) = 0 \\
y^T(F^Tv-B^Tx) = 0 \\
Ex = e \\
Fy = f\\
E^T u - A y \geq 0 \\
F^Tv - B^Tx \geq 0 \\
x, y \geq 0
\end{align*}

\noindent These conditions collectively define a mixed linear complementarity problem (LCP). The word "complementarity" refers to the fact that because $x$, $y$, $A$, and $B$ are nonnegative, the first line implies that $x$ and $E^Tu-Ay$ cannot have a positive component in the same position. The same holds for $y$ and $F^Tv-B^Tx$. The best known algorithm for finding a solution to a linear complementarity problem is that of Lemke and Howson (1964) \cite{lemkehowson}. 

Even this algorithm, which is beyond our scope here, is inadequate to the settlement bargaining problem. The problem is that the bimatrix game will be too large. When an extensive form game is converted to a matrix, the matrix must contain a separate row for all permutations of the choices that the row player may make at an information set, and similarly a column for each permutation of the column player's information set choices. For example, if each player has 10 different information sets (perhaps corresponding to 10 different possible signals), and may make 10 different moves at each information set, then $10^10$ rows or columns would be needed for that player. Several different scholars, the earliest being Romanovskii (1962) \cite{romanovskii}, offer a way around this dilemma. The trick, as explained by Koller, Megiddo, and von Stengel (1996) \cite{kollermegiddovonstengel}, is to craft a matrix in which the rows or columns represent not a player's pure strategies, but instead the sequences that the player may play at any stage of the game. In the above example, there would be 101 sequences per player (10 for each information set plus an empty sequence). If we inserted an opportunity by each player to quit after receiving its signal, then there would be 121 sequences per player (the above, plus decisions to quit or not at each of the 10 signals). Some sequences may be incompatible, because it may be impossible for a player to play a certain information set given a move by another; thus, the relevant matrix includes a zero in such cells. 

The von Stengel, van den Elzen, and Talman (2002) algorithm adapts the "sequence form" approach by combining techniques used in von Stengel (1996) with developments in van den Elzen and Talman (1999), which adapts the Lemke-Howson algorithm to ensure perfect equilibria. The result is an algorithm that produces perfect, Nash equilibria. The requirement of perfection would not be needed if players committed to strategies at the outset of the game. But in litigation, such commitments do not occur. Thus, even if an equilibrium meets the Nash criterion, meaning that neither player will have an incentive at the outset of the game to change its strategy choice given the opponent's strategy choice, it may be imperfect, if a player might have an incentive to deviate in its strategy choice after learning new information. The solution concept of perfect Bayesian equilibrium, a term in use since at least the 1960s, has various formal definitions in the literature, including that of Fudenberg and Tirole (1991) \cite{fudenberg}, and is the imperfect information analogue of the subgame perfection equilibrium concept proposed by Selten (1965) \cite{selten}.

The algorithm is initialized by setting every information set to a fully mixed behavior strategy, that is a strategy in which each action has some positive probability of being played. A data structure called a tableau is initialized in turn based on these values. This tableau encodes not only action probabilities, but also the relationships among information sets, specifically which information sets may follow other information sets in sequence. The initialization is designed so that the equations reflected by the tableau reflect a "basic feasible solution" to some of the equations in the linear complementarity problem, albeit ordinarily not a solution that corresponds to a perfect Nash equilibrium.  The algorithm then proceeds through a series of pivoting steps, which represent  linear algebraic manipulations in which variables are added to or removed from the list of non-zero variables known as the basis. When the variable initially added to the basis eventually leaves the basis, a Nash equilibrium is guaranteed.

The algorithm is not without its limitations. First, the algorithm is not guaranteed to produce all Nash equilibria. One may attempt to obtain multiple equilibria by choosing different initializations of the information sets. Second, to ensure that an equilibrium is reached, the algorithm must be performed using exact arithmetic with rational numbers, rather than floating point arithmetic. Even given the generous amount of storage allowed by modern 64-bit computer architectures, floating point operations involve rounding, and that may prevent the algorithm from converging.  The use of exact arithmetic is cumbersome, however, given the frequent need to calculate greatest common factors of integers with many digits. Third, the algorithm is roughly linear in the size of the game tree, not in the size of the set of player sequences. The game tree grows exponentially as more moves are added to the game.

\subsection{A Near Replication} \label{replication}

One approach to using the algorithm is to attempt to replicate Dari-Mattiacci and Saraceno as closely as possible. Such an attempted replication requires restriction of each player's bid function to consisting of piecewise linear segments. Yet, there are an infinite number of possible combinations of piecewise linear segments, and so we must adopt some restrictions. In theory, we could, for example, require each player to choose one of 100 starting values and one of 100 ending values for each of 10 signal ranges; for example, plaintiff might bid $0.47$ at $z=0.5$ and $0.92$ at $z=0.6$, representing one such segment. But, for each player, this would produce $(100 \times 100)^10$ possible strategies, and the game tree would be the square of this in size. 

For this approach to run in a feasible amount of time, the strategies must be severely constrained. We thus allowed each player to choose a line with a minimum value in $\{0.02, 0.06, 0.10, ..., 0.98\}$, and a slope in $\{ \frac{1}{3}, \frac{1}{2}, \frac{2}{3}, 1 \}$. Because truncations are critical to the Dari-Mattiacci and Saraceno equilibria, each player also could choose a truncation portion from $\{0, \frac{1}{9}, \frac{2}{9}, ..., 1\}$; for example, when the plaintiff's strategy contains a truncation value of $\frac{1}{3}$, then the plaintiff's minimum bid is set equal to the minimum value selected plus $\frac{1}{3}$ of the slope. Thus, each player may in effect choose from $25 \times 4 \times 10 = 1,000$ strategies, so the game tree is thus quite large, consisting of 1,000,000 final nodes, even though the strategies are quite constrained. At each of these final nodes, the players' utilities are calculated by determining, for each of 10,000 combinations of the players' signals, the outcome of the game given the players' strategies. 

Figure \ref{fig:replication1} illustrates a result of the algorithm, in this case for parameters $q = 0.4$, $c = 0.2$, and $t = 0.4$. The panels on the left represent the plaintiff's strategies; on the right, the defendants. The results of the computational model, on the bottom, are reasonably similar to the equilibrium for these parameters identified in the analytical model of Dari-Mattiacci and Saraceno, on the top, though hardly an exact match. This result is an exact equilibrium in the game as defined with these restrictions, but it is only an approximate equilibrium in the original Dari-Mattiacci and Saraceno game, which does not impose these restrictions. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/replication1.pdf}
\caption{Attempted replication with $q = 0.4$, $c = 0.2$, and $t = 0.4$}
\label{fig:replication1}
\end{figure}

Still, by combining a number of such parameter sets, one can perform a task similar to that of Dari-Mattiacci and Saraceno, observing how changes in parameters affect the equilibrium. The results of a number of such observations are available in the Online Supplement to this article in the "DMS Replication" folder, corresponding to parameter values that are multiples of $0.1$ that meet Dari-Mattiacci and Saraceno's assumptions regarding $q$ and $c$ and for which in their analytical model neither party's strategy consists of more than a single line segment. The results in Figure \ref{fig:replication1} are typical, though there are some surprises, like Figure \ref{fig:replication2}, in which the algorithm calculates a mixed strategy equilibrium, with the relatively darkness of each of the parties' strategies corresponding to the probability that a party will play them. Though it seems unlikely that any individual would play such a strategy, a mixed strategy can be interpreted as a set of pure strategies that might be played by different litigants, where neither litigant knows the other litigant's type. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/replication2.pdf}
\caption{Attempted replication with $q = 0.4$, $c = 0.3$, and $t = 0.6$}
\label{fig:replication2}
\end{figure}

Although these results illustrate that the algorithm can approximately replicate some analytical results, they may be disappointing. The most interesting results of Dari-Mattiacci and Saraceno occur in cases in which the strategies are discontinuous, and we have not even attempted to replicate those cases. The reason that the algorithm performs so weakly is that it does not fully take advantage of the sequence form. Each party has a limited number of information sets, in many of which it considers a large number of possibilities (such as which of 25 minimum values to select) that in turn dictate the party's strategy over a range of signals. The result is not much better than could be achieved by applying iterated elimination of dominated strategies. Still, the exercise is sufficiently simple that one might wonder why the settlement bargaining literature has eschewed even that well known technique. Even if it is practical to represent only 1,000 strategies per player, as here, this technique at least is a step beyond the prior literature in using computation to identify Nash equilibria in settlement bargaining games, and it is a technique that can be applied to a wide range of game specifications. 

\subsection{A Discretized Evidentiary Signals Game} \label{gametree}

A seemingly less ambitious but ultimately more fruitful strategy relies each player of the obligation to produce a bid function mapping every signal to an offer. Instead, we can discretize the signal, so that each party receives a discrete signal from $n_S$ possible signals and then must make a discrete offer from $n_{\mathcal{o}}$ available offers. For legibility, Figure \ref{fig:gametree} illustrates a highly simplified version of this game for  $n_S=2$ and $n_{\mathcal{o}}=2$, but we will generally use  $n_S=10$ and $n_{\mathcal{o}}=10$, which produces a game tree consisting of 11,111 nodes. The circles identify the players (Chance, Plaintiff, or Defendant), as well as information set numbers. The plaintiff does not observe the signal received by the defendant and vice-versa. Thus, for example, at each of the four points in the tree labeled as "D0," the defendant has the same information set, in which it has received the signal 1 (corresponding to $z=0.25$) instead of the signal 2 (corresponding to $z=0.75$). Thus, the defendant must assign the same move probabilities to its two alternative offers (corresponding to 0.25 and 0.75) at each of these points. The diagram illustrates an equilibrium identified by the algorithm for this simple game, in which each player is always aggressive, with the plaintiff demanding 0.75 and the defendant offering only 0.25. Given the Chaterjee and Samuelson bargaining protocol, this does not result in a settlement.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{The game tree with $n_S=2$ and $n_{\mathcal{o}}=2$}. 
\label{fig:gametree}
\end{figure}

The strategies permitted with this approach are in some ways more constrained and in some ways less constrained than the strategies in Dari-Mattiacci and Saraceno. The analytical model, of course, does not restrict the signals or offers to the 10 discrete points for each that we will allow for each set of parameters. But it does restrict the litigants from playing nonlinear strategies between the points that produce discontinuities in their proferred equilibria. The computational and analytical approaches both impose admittedly arbitrary constraints on what strategies are permissible. This is, of course, not unusual, and it is common in the settlement bargaining literature to see tighter constraints, such as in models where a party receives one in two signals instead of one in ten. An important question, however, is whether the discretization dramatically changes the nature of the equilibrium.

We can test that ...

relax Dari-Mattiacci and Saraceno's assumption that each player has a piecewise linear strategy, which allows at signal values that can be calculated to produce kinks in the party's expected litigation results. 

[HOW DO WE KNOW THIS WORKS]

To use a computational approach that finds equilibria from extensive form game trees, the model must encompass a discrete number of values representing the strength of the plaintiff's case, the signal that each party receives about the strength of the case, and the settlement values that each party can offer the other. In most of the simulations, we will allow for $n_{LS}=10$ quality levels on the issue of liability, $n_{LS}^P=n_{LS}^D=10$ signals of liability strength for each of the plaintiff and defendant on the issue of liability (damages will be considered separately later), and  $n_{\mathcal{o}}=10$ offers for each party. 

A model dependent on discrete variables is admittedly less general than a model based on continuous quantities, and a virtue of the mathematical literature on settlement bargaining is that some variables can be modeled continuously. In Bebchuk (1984), for example, the defendant knows the probability that the court will find liability, which can be any value from a mutually known probability density function. But not all variables in mathematical settlement models are continuous. In their review of the settlement bargaining literature, Daughety and Reinganum (2012) \cite{daughetyreinganum2012} include both two-types and continuous types models. Even models that offer continuous types in one respect feature only two types in another respect. For example, Klerman, Lee, and Liu (2018) \cite{klermanleeliu} allow each party to obtain a continuous signal of the quality of litigation, but the quality itself can take on only one of two values. Moreover, the one-sided asymmetric information models of litigation can be considered one-type models, at least with respect to the party without information.  Thus, the conventions of the existing literature do not mandate continuous variables. The 10 quality levels and signals of liability strength for each party allow a considerably greater degree of granularity than two-types models. 

To describe the litigation game, however, it is easier to focus on a much smaller game tree, where $n_{LS}=n_{LS}^P=n_{LS}^D=n_{\mathcal{o}}=2$. This smaller game tree, including probabilities corresponding to a perfect equilibrium of the game (produced to three decimal places), is presented in Figure \ref{fig:gametree2x2x2}. This is presented in full at the expense of legibility to illustrate that even with these low parameter values, the game tree is fairly large. (The full figure is available in the Supplemental Materials.) Thus, we will simplify further, focusing on particular parts of the game tree.
\begin{figure}[h!]
\centering
\includegraphics[width=10cm, height=10cm, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{A bird's eye view of a small game tree}
\label{fig:gametree2x2x2}
\end{figure}

Figure \ref{fig:gametree2x2x2beginning} illustrates the beginning of the litigation game. The first decision in the game belongs neither to the plaintiff nor the default, but to Chance, abbreviated C, a nonstrategic player. This common device, known as the Harsanyi transformation after Harsanyi (1967) \cite{harsanyi}, effectively creates a random number generator, transforming a game of perfect but incomplete information (where each player knows all moves that have been made but does not know payoffs) into one of complete but imperfect information (where a player may not know of some moves, such as Chance decisions revealed only to another player, but knows the complete game structure). Chance's initial decision in this game is whether the case is one in which the defendant is truly liable or one in which the defendant is not truly liable. Chance chooses true liability with a probability $p_{TL}$, here $\frac{1}{2}$. 

Explicit modeling of true liability will allow us ultimately to measure the accuracy of outcomes explicitly. A less ambitious approach would be to define accuracy solely based on whether settlements mimic resulting judgments, but that would ignore the imperfections of judgments themselves. A more ambitious approach, to be pursued in future work, would be to model the emergence of disputes endogenously in some particular legal context, as in Hylton \cite{hylton}, in which a potential tort defendant initially makes a decision about taking care. The approach here, however, is more general, and by varying Chance's probabilities, we will be able to change the distribution of true liability. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{The beginning of the small game tree}
\label{fig:gametree2x2x2beginning}
\end{figure}

Chance then immediately faces a second decision, what the strength of the plaintiff's case on liability should be. Using the baseline parameters (to be described below), when the defendant is not truly liable, there is an 85.1\% chance that the liability strength will be low, and when the defendant is truly liable, there is an 85.1\% chance that the liability strength will be high. This approach recognizes that although there will generally be a correlation between true liability and the strength of a plaintiff's case, there may be cases in which a plaintiff has a weak case despite true liability, or a strong case despite absence of true liability. By separating true liability from the strength of the liability case, we can assess how the strength of the legal system, defined loosely here as the correlation of true liability with case strength, affects the case for fee-shifting. 

Each case has a liability strength that is a noisy signal of the true liability value. Then, each party in turn receives a noisy signal of the liability strength,  As illustrated in Figure \ref{fig:gametree2x2x2beginning}, if the liability strength is low, then the plaintiff is more likely to receive a low signal than a high signal, and vice versa if the liability strength is high. The defendant's signal is determined independently of the plaintiff's, but the two are correlated, because each is determined in part by the true liability level. Although the game tree imposes an ordering, making it appear that the Chance decision determining the plaintiff's signal occurs before the Chance decision determining the defendant's signal, that is irrelevant and has no effect on equilibrium determination, because the defendant does not learn of the plaintiff's signal and vice versa.

Figure \ref{fig:liabilitysignalsdefault} provides a simple visualization of the probabilities of different liability strengths given the true liability status, and of the probabilities that a player will receive different liability signals. These probability values correspond to the baseline values that this article will use in its simulations. The degree of noise is admittedly somewhat arbitrary. A future project would be to calibrate signals based on empirical data for some particular category of cases, but the observation of Gelbach (2018) \cite{gelbach} that many very different models may share a common reduced form suggests that this will be challenging. An informal assessment based on Figure \ref{fig:liabilitysignalsdefault} might conclude that the assumed noise values chosen correspond to a legal system that is pretty good. It is relatively rare, for example, for a truly liable case to have a below-average liability strength signal, or for a party to receive a signal indicating likely liability when the actual liability strength is below average. This point highlights that the highly strategic play and relatively low settlement rates that we will observe with risk neutrality are not the result of weak party information. We will, however, also consider the effects of both stronger and weaker information, as well as of asymmetric information.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.4, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Liability strength given true liability and party's signal given liability strength}
\label{fig:liabilitysignalsdefault}
\end{figure}


A litigation game equilibrium can be calculated for any distribution of signals given true values, so a modeler could simply exogenously specify the conditional probabilities illustrated in Figure \ref{fig:liabilitysignalsdefault}. It is useful, however, to encapsulate the degree of noise into simple parameters. The probabilities of liability strengths in Figure \ref{fig:liabilitysignalsdefault} depend on a parameter $\sigma_{LS}$, which represents the standard deviation of a normal distribution from which noise values are drawn. A noise value is summed with a value taken from the true liability Bernouilli distribution, so the greater $\sigma_{LS}$, the more attenuated the connection between whether a defendant is truly liable and what the liability strength is. The signals of liability strength that the plaintiff and defendant receive depend on the similar parameters $\sigma_{LS}^P$ and $\sigma_{LS}^D$. In the baseline simulations represented in Figure \ref{fig:liabilitysignalsdefault}, $\sigma_{LS}=0.35$ and $\sigma_{LS}^P=\sigma_{LS}^D=0.20$.

More formally, the unit interval is divided into $n_{LS}$ equal segments, corresponding to the $n_{LS}$ values. The probability of each liability strength level is equal to the relative probability that the sum falls into the corresponding segment, ignoring sums less than 0 or greater than 1. That is, let $TL=\{0,1\}$ represent the possible true liability values, corresponding to not truly liable and truly liable, respectively; let $LS_i=\frac{i - \frac{1}{2} }{n_{LS} }$ for $\forall i \in \{1,2,...,n_{LQ}\}$ represent the set of liability strength values; and let $N_{LS,k}=\langle\sigma_{LS}\Phi^{-1}(\frac{i}{k}) \rangle_{i=1}^{k-1}$ represent a sequence of $k-1$ noise values drawn from the inverse normal  distribution with standard deviation $\sigma_{LS}$. Then, $\forall t\in TL$, let 
\begin{equation} 
p_{LS_i|t} = \lim_{k\to\infty} \frac{\lvert\{t+\nu |\nu \in N_{LS,k}, LS_i - \frac{1}{2n_{LS} }<t+\nu \leq LS_i + \frac{1}{2n_{LS} }\}\rvert}{\lvert\{t+\nu |\nu \in N_{LS,k}, 0<t+\nu \leq 1 \}\rvert}
\end{equation}
represent the probability that the signal with index $i$ is received given a truly liable value of $t$.

For player $j$, the probability of receiving a particular signal of liability strength can be calculated as
\begin{equation} 
p_{LS_i^j|LS_i} = \lim_{k\to\infty} \frac{\lvert\{LS_i+\nu |\nu \in N_{LS,k}, LS_i^j - \frac{1}{2n_{LS} }<LS_i+\nu \leq LS_i^j + \frac{1}{2n_{LS} }\}\rvert}{\lvert\{LS_i+\nu |\nu \in N_{LS,k}, 0<t+\nu \leq 1 \}\rvert}
\end{equation}

\noindent The volume of the flows from the "not truly liable" and "truly liable" nodes to each of the liability strength nodes correspond to the $p_{LS_i|t}$ probability values, and the volume of the flows from the liability strength nodes to the signal nodes correspond to the $p_{LS_i^j|LS_i}$ values. 

Returning to our smaller game tree with just two liability strengths and two signals for each party in Figure \ref{fig:gametree2x2x2beginning}, each path leads to a decision to be made by the plaintiff. An information set number is indicated next to the "P" indicating plaintiff. The information sets labeled "P0" correspond to the cases in which the plaintiff receives the low signal of liability strength, while the information sets labeled "P12" correspond to the cases in which the plaintiff receives the high signal. (The missing information set numbers between 0 and 12 appear in the endgame, to be presented momentarily.) This signifies that the plaintiff cannot distinguish among all of the cases within each information set. That is, the plaintiff does not know whether the case is one that is truly liable or not truly liable, and the plaintiff does not know whether the defendant receives a low signal or a high signal. The plaintiff's equilibrium strategy must be optimal given the constraint that the probabilities that the plaintiff assigns to its next move must be the same, regardless of the true liability and of the defendant's signal, and thus conditional only on the plaintiff's signal. 

Figure \ref{fig:gametree2x2x2end} illustrates the decision to be made by the plaintiff at the "P0" information set, corresponding to the very top line in Figure \ref{fig:gametree2x2x2beginning}. The decision is whether to file suit. In this equilibrium, we can see that the plaintiff always files suit in this information set. If, however, the plaintiff did not file, then the game would end, with each player receiving a utility of 10. The value 10 is an arbitrary value used to represent each party's initial wealth; because this particular game tree represents risk neutral utilities, the initial wealth is irrelevant, and the equilibrium would be exactly the same for any linear transformation of one or both players' utility values. If the plaintiff does file suit, then the plaintiff will incur a cost $c_{file}$, which is equal to 0.15 in this version of the game tree. The defendant then faces a decision whether to answer, which also causes the defendant to incur a cost $c_{answer}=0.15$. If the defendant does not answer, then the plaintiff wins, and the defendant pays damages that in all simulations in this article are normalized to 1.0. Thus, plaintiff receives a utility of 10.85, and the defendant, 9.0.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{The end of the game tree}
\label{fig:gametree2x2x2end}
\end{figure}

Assuming that the plaintiff files and the defendant answers, then the plaintiff faces a decision whether the plaintiff will abandon the litigation rather than incur trial costs if settlement fails, and the defendant similarly faces a decision whether to default in the event settlement fails. Neither party's decision has any immediate effect, and neither party finds out about the other party's decision. The placement of these decisions before settlement rather than after is admittedly counterintuitive. But it greatly speeds up the algorithm for calculating equilibria, relative to a model in which each player takes into account both its own settlement offer and its opponent's in deciding whether to quit. With the latter approach, there would be one information set for each player for each triple of a liability signal, a settlement offer, and an opponent's settlement offer. By deciding abandonment or defaulting in advance, we greatly reduce the number of information sets in the game, with just one information set concerning quitting for each liability signal for a player. Although it might be interesting to study the strategic interaction in a model in which a party's offer may affect the opponent's decision whether to quit, that is beyond our scope here. Including decisions whether a party will abandon or quit litigation continues to serve its primary role of affecting bargaining indirectly, by forcing each party to consider in making a settlement offer whether its opponent has a credible threat to take a case to trial. Commentators including Huang (2004) \cite{huang} and Hubbard (2016) \cite{hubbard} have stressed that even if quitting just before trial is rare, the possibility of such quitting may discipline decisions on whether to file or answer, as well as settlement offers.

Whatever the future plans the parties make about whether to abandon or default, each party makes a settlement offer to the other party. In the diagram, it appears that the plaintiff makes an offer before the defendant, but this timing is again irrelevant. Note that the defendant faces the same information set regardless of whether the plaintiff makes a low offer or a high offer. That is, the defendant does not learn the plaintiff's decision before it makes its own, so the decisions are effectively simultaneous. 

The bargaining protocol used is that introduced by Chatterjee and Samuelson (1983) \cite{chatterjeesamuelson}. If the plaintiff's offer exceeds the defendant's, the case settles at the midpoint; otherwise, bargaining has failed, and, unless a party has decided to quit, the case goes to trial. As Friedman and Wittman \cite{friedmanwittman} explain, this choice is justified not on the ground that the protocol is commonly used (it is not), but on the ground that it provides a useful reduced form of a more complicated bargaining process. While future work might employ some other bargaining protocol, such as back-and-forth offers between the parties, that would exponentially increase the number of information sets and the amount of time needed for the algorithm to run. Chaterjee-Samuelson bargaining avoids the simplification in the Landes-Gould-Posner bargaining models of assuming that a case will settle whenever that is in the mutual interest of the parties, given their expectations. With Chaterjee-Samuelson bargaining, parties have some incentive to shade their offers in their own favor in the hope of capturing more of the settlement surplus, though they must balance this objective with the risk of bargaining failure. The approach thus allows for an important dimension of strategic bargaining, while avoiding the simplification adopted by models that arbitrarily choose a player to make a take-it-or-leave-it offer to the other player.

Finally, at the far right end of Figure \ref{fig:gametree2x2x2end} are the utilities received by the players in cases that settle, as well as the further game play in cases that do not settle. If a case does not settle, but one player previously decided to quit in the event of settlement failure, then the game immediately ends without trial. If both players decided to quit, which in practice is likely to occur only when the cost of trial is much greater than the level in Figure \ref{fig:gametree2x2x2end}, then a chance decision assigns each a 50\% chance of quitting, as demonstrated near the top right of the diagram. In the more important case where neither party quits after settlement failure, trial occurs. Each party is charged a cost of $c_{trial}=0.15$, and  the court must determine whether to impose liability. The court makes its decision based on a noisy assessment of liability strength, must as the players do; thus, the modeling allows not only for liability strengths that differ from truth but also for different levels of judicial idiosyncracy. The parameter determining the noisiness of the signal that the court faces is the same as that for the players, $\sigma_{LS}^C=0.2$. The court, however, observes one of only two liability signal levels. If it observes the higher level, the court imposes liability. In this game tree, no fee shifting occurs, so liability results in a transfer from the defendant to the plaintiff of 1.0.  Note that the court is making an inference based on its signal, but this is not a fully Bayesian inference. The court does not take into account the initial distribution of disputes, and it does not refine its inferences based on game play, for example by determining whether a failure of settlement is more likely when the defendant is or is not truly liable. A project for future work, more in the spirit of the mechanism design literature such as Spier (1994) \cite{spier}, would be to make the court an additional player in the game that can determine the level of damages and seeks to optimize social welfare.

The game tree can be simplified when calculating equilibria. The Chance decisions determining true liability and the liability strength do not directly result in any information being added to the plaintiff's or defendant's information set. The only information from a Chance decision that matters to the litigants is the signal of liability strength. We can thus skip the first two Chance decisions and jump directly to the stage where the plaintiff receives a signal, so long as the probabilities of each signal are the same for the plaintiff and so long as the probabilities that the defendant receives each signal conditional on any signal received by the plaintiff remain the same. Figure \ref{fig:gametree2x2x2beginning_reduced} shows a reduced form version of the beginning of the game tree. The probability that the defendant receives the same signal as the plaintiff, 79.2\%, can be computed in the larger game tree by weighting the probability of different branches. Using this reduced form will produce the same equilibria as will result from following Figure \ref{fig:gametree2x2x2beginning}. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{A reduced-form version of the beginning of the game tree}
\label{fig:gametree2x2x2beginning_reduced}
\end{figure}

The end of the game can also be simplified. The court's eventual decision on liability affects the players, but a model in which a player receives the expected value of the court's decision with certainty produces identical equilibria. Meanwhile, in the rare circumstances when both parties decide to quit, resolving the case at an average of the utilities that would obtain when one quit produces the same result as flipping a coin to determine whether the plaintiff wins or loses. In both cases, this works regardless of risk aversion level, so long as the final outcomes are utilities, rather than risk levels. Figure \ref{fig:gametree2x2x2end_reduced} illustrates the reduced-form version of the end of the game tree in the very small game.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{A reduced-form version of end of the game tree}
\label{fig:gametree2x2x2end_reduced}
\end{figure}

The full game tree will still be needed to calculate variables such as party win rates at trial and accuracy of the system of litigation. Thus, after the equilibria are calculated using the simplified version of the tree, the full tree can be explored to determine the exact probability of every outcome. None of the results in this article depends on Monte Carlo sampling, and so no error bars are needed, given the exact equilibrium identified by the algorithm.

\section{Results} \label{results}

In addition to furnishing a much more complex game tree than theorists have been able to achieve with pure math models, the computational game theory approach applied here enables many changes to the litigation game to be made with no increase in algorithmic complexity. Any change that affects only the players' utilities leaves the game tree the same size, and so the time needed for modeling needs to be multiplied only by a constant factor representing the number of different permutations of parameter values to be tested. Some considerations that are difficult to model mathematically are trivial computationally. Risk aversion, for example, is ordinarily complex to model, and different forms of utility function may require separate proofs, as in Park and Lee (2019). The approach here easily accommodates changes in the degree or form of risk aversion. Similarly, changes to the costs the parties bear and the quality of their information add no complications. Different fee-shifting rules and intensity of fee shifting, including requirements that the loser pay a multiple of legal fees, can easily be integrated in the model. 

This section thus considers a wide range of potential variations of its settlement bargaining model. The analysis begins with the baseline parameter values defined in the game illustrated in Figure \ref{fig:gametree2x2x2} (but with $n_{LS}=n_{LS}^P=n_{LS}^D=n_{\mathcal{o}}=10$), while varying costs and fee shifting multipliers. The parameter values are admittedly not yet calibrated to actual data, but real world parameter values are likely to vary from place to place and case category to case category in any event. Probably the most important parameter, other than the fee-shifting rule, that may vary across suits is the cost relative to the stakes. The litigation may play out very differently in a small claims case, in which total costs to litigants including lawyers and their own time will generally be high as a percentage of the stakes, than in a multi-billion dollar suit in which even the priciest lawyers will charge only a small fraction of what is at issue. Thus, even when varying other parameters, simulations considering various permutations of costs and the fee-shifting multiplier are included. Space limitations prevent us from reporting all findings here, but spreadsheets and diagrams for each simulation are available in the Supplemental Materials, including over 20,000 diagrams in PDF or Latex form, and simple changes in the source code can be used to test combinations of parameters not already simulated.

\subsection{Baseline comparison} \label{baseline}

Before varying costs, we will scrutinize the results of two simulations, the simulation corresponding to the baseline parameter values and the identical simulation except applying the British rule, so that if a case goes to trial, the loser pays the winner's costs. The model does not differentiate whether these costs are in the form of attorney fees, court costs, or litigants' time. Figures \ref{fig:fileans_american} and \ref{fig:fileans_british} illustrate the plaintiff's decision whether to file suit and the defendant's decision whether to answer (conditional on filing) in the identified equilibria. Although models like Shavell (1982) \cite{shavell} suggest that the British rule will reduce the likelihood that a plaintiff with a low likelihood of winning will file suit, no such effect is visible in these figures, as the plaintiff's decisions are identical. The defendant's decisions are almost identical too, except that when the defendant receives a signal of 0.65, the defendant has a 4\% chance of answering under the British rule, in contrast to the American rule, where the defendant never answers. 

The unexpected stasis helps illustrate the power of computed equilibria to identify dynamics not apparent in simpler models. This result is a consequence of multiple competing pressures that balance one another, pressures that would not be evident in a game that did not feature file/answer decisions, settlement offers, and decisions whether to give up after the failure of settlement. Consider a plaintiff who receives a signal of 0.35 and is thus near the margin of deciding whether to file suit. The British rule does indeed provide further impetus in the direction of not filing suit. On the other side of the liability signals spectrum, the defendant faces similar pressure not to answer. Fee shifting, however, also gives this plaintiff a greater incentive to drop the suit rather than face trial costs if settlement fails. That change in turn makes it more attractive for the defendant to fight, toughening the defendant's settlement negotiation stance. These changes can lead to further hydraulic pressures that just happen in this example to approximately cancel out. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{File and answer decisions (American rule)}
\label{fig:fileans_american}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{File and answer decisions (British rule)}
\label{fig:fileans_british}
\end{figure}

It might seem that this is a "just so" story and that one could construct many narratives to explain how changing a parameter leads to some change (or in this case, no change) in some decisions by the parties. Indeed, the equilibrium dynamics are sufficiently complicated that we should resist the temptation of overinterpretation. But  we can directly observe at least the immediate pressures on the file and answer decisions that result from changing from the American to the British rule. Specifically, we can change the players' utility payoffs to those that obtain with fee shifting, but retain the strategies that they play under the American rule equilibrium. Then, we can examine the utilities that each player can expect to receive at each information set. Because an information set may correspond to multiple nodes of the game tree, these utility values are the expected utilities from choosing each action at a node, weighted by the probability of reaching that node in the game tree. At equilibrium, the actions with positive probability must all have the same, maximal expected utility (otherwise, we would not be at perfect equilibrium), but changing the payoffs can alter this. We can thus identify actions that the player would choose more often, assuming that all other aspects of both parties' strategies remained fixed. 

This analysis (contained in the Supplemental Materials under the Supplemental information folder) demonstrates, for example, that, holding all else equal, the plaintiff's nonsuit rate would increase by 6.4 percentage points, and the defendant's default rate by 4.4 percentage points, if changing to the British rule while holding the other party's strategy constant. It also demonstrates how changing these values in turn would lead to the other effects described in the previous paragraph. The technique thus provides some intuition for why switching to the British rule might not lead the parties to contest litigation less often. The words "might not" highlight not that we should be unsure about whether the equilibria partially depicted in Figures \ref{fig:fileans_american} and \ref{fig:fileans_british} really exist \textemdash they do, and the source code confirmed that they are in fact perfect Nash equilibria, though of course we cannot be sure that human beings will play according to the equilibria \textemdash but that we must be attentive to the possibility that different results might obtain with other parameter values. 

We will return to exploring other parameter values, but first let us consider the offers that the parties make, conditional on the signals that they received. This is illustrated in Figure \ref{fig:offers_american} for the American rule, and Figure \ref{fig:offers_british}, for the British. Some columns feature no offers; these are the same columns for which the parties did not contest litigation. What is striking about the offers that the parties make is that they are stingy. When the plaintiff receives a signal of 0.35, the plaintiff insists on a settlement of no less than 0.75. (Recall that under Chaterjee-Samuelson bargaining, the case will settle only if the defendant's simultaneous offer is greater than or equal to the plaintiff's.) The defendant, meanwhile, when receiving a signal of 0.55 will offer no more than a nuisance settlement of 0.15. And the parties are stingier still when moving toward the extremes, at which each party insists on the stingiest possible settlement. One might have the intuition that settlement offers would rise roughly linearly with signals and that close cases would settle for middle-range values. After all, the parties do have a monetary interest in avoiding trial. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Offer decisions (American rule)}
\label{fig:offers_american}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Offer decisions (British rule)}
\label{fig:offers_british}
\end{figure}

That strategic bargaining might occur is not surprising. All of the Bayesian models of settlement that use Chaterjee-Samuelson bargaining (including Friedman and Wittman (2007) \cite{friedmanwittman}) recognize that each party faces a trade-off: Greater generosity increases the chance of avoiding trial, but greater stinginess increases the portion of the bargaining surplus that the offeror will receive if a settlement does occur. But strategic bargaining plays a considerably larger role than one might expect. Recall from Figure \ref{fig:liabilitysignalsdefault} that the amount of noise obscuring each party's evaluation of the merits does not seem all that large, and yet considerable strategic behavior manifests. The pattern of offers observed here is hardly invariant, but settlement behavior of this sort occurs under a wide range of parameter values, especially when the parties are risk neutral. Real-world bargaining includes many features not accounted for in this model, but this result tentatively suggests that litigants might rationally often fail to reach settlements even when their actual assessments of the litigation value are not far apart. At least, these results should make us cautious about accepting at face value the results of Landes-Posner-Gould models that assume settlement occurs whenever settlement would produce social surplus.

The considerable extent of strategic bargaining does have an upside for this project. If the analysis revealed that parties' settlement offers were often very close to each other, then one might worry that the discreteness of action choices in this game theoretical model might be affecting results. Suppose, for example, that a change in some parameter would lead in a continuous model to slight changes in the parties' settlement functions that nonetheless had large effects on the settlement rate. It would be hard for a discrete model, in which each party must choose among only ten offer levels, to capture that nuance. The discreteness of the model with respect to some variables that may be continuous in mathematical models may indeed be the most serious weakness of the approach described here relative to a mathematical model. But in a world in which parties make either stingy or generous offers, but with little in between, a model with ten offer level choices seems likely to be able to capture, at least approximately, the bargaining dynamics.

Figures \ref{fig:errors_american} and \ref{fig:errors_british} offer a visualization of how the plaintiff's file decision, the defendant's answer decision, the parties' offers decisions, and to a much lesser extent their decisions whether to quit after settlement failure, directly affect the variables of ultimate interest: accuracy and expenditures. Inaccuracy is defined in two different (though generally highly correlated) ways: as false negatives or false positives. A false negative inaccuracy is measured from the perspective of the meritorious plaintiff. Every dollar by which the plaintiff's net recovery \textemdash that is, damages received minus plaintiff's litigation expenditures \textemdash falls short of what the plaintiff ideally would receive from a truly liable defendant in a hypothetical perfectly accurate and costless legal system counts as a false negative dollar. A false positive inaccuracy is measured from the perspective of the truly not liable defendant. Every dollar that such a defendant spends, whether on litigation or in damages, counts as a false positive dollar. These values can be calculated directly, because the model explicitly calculates the proportion of cases in which the defendant is truly liable or not. The mathematical modeler, as we will see later, may need to resort to much less direct measures of inaccuracy that fail to take into account actual litigation expenditures.

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Errors and expenditures (American)}
		\label{fig:errors_american}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures (British)}
		\label{fig:errors_british}
    \end{minipage}
\end{figure}

Figures \ref{fig:errors_american} and \ref{fig:errors_british} provide a clean visual depiction of both error costs and expenditures, which have social welfare significance independent of their effects on accuracy. Nonetheless, these diagrams may require some explanation. Every case is accounted for on the vertical axis, and cases are ordered by their type of disposition, with cases in which the plaintiff doesn't file suit and the defendant does not answer at the bottom, and cases that settle (under these parameters, only with the British rule), that result in a party quitting after settlement failure (just a few cases with the British rule, too narrow to fit a label), or that result in a trial with the plaintiff losing or winning pile on toward the top. In areas of the diagrams where the false negatives and false positives are empty, this is because those cases do not produce any false positives. For example, the vast majority of cases in which the plaintiff does not file suit are cases in which the defendant is truly not liable, so this resolution is nirvana, producing zero error costs and zero expenditures. A few cases, however, are cases in which the defendant is truly liable, resulting in false negatives, represented by the rectangle with north east lines in the bottom left of the figure. (All diagrams are designed with patterns to be presentable in black and white, but the color versions, in which this box is blue, are available in the Supplemental Materials.) The height of this rectangle represents the proportion of cases of this type, and the width represents the size of the false negatives, large but not as great as would be if the parties spent money on litigating first. 

The cases in which the defendant does not answer produce similarly low error rates, but not as low, because the plaintiff bears the filing costs. When cases settle, there are some false positives and false negatives, as well as a moderate amount of expenditures from both parties' initial expenditures. Finally, when the cases go to trial, expenditures are at their maximum, and because the court is not perfect, some errors result: false positives when a nonmeritorious plaintiff wins and false negatives when a meritorious plaintiff loses. Expenditures may cause some inaccuracy even in cases in which the correct party wins. For example, when the plaintiff loses in a case in which the defendant truly is not liable, under the American rule, the defendant suffers a false positive as a result of litigation expenditures. Similarly, when the plaintiff wins in a case in which the defendant truly is liable under the British rule, no false negatives occur because the plaintiff receives full compensation, but the defendant suffers false positives from paying even more than damages in total.

In short, the area of the rectangles represents the total size of the false negatives, false positives, and total expenditures. Thus, one can at a quick glance appreciate the social welfare effects of fee shifting, holding all other parameter values constant. In this example and in most others, the effects are not all that great. Still, the British rule may have a slight edge. The British rule fails to increase the chance that the plaintiff will not file or that the defendant will not answer, a change that at least at the margins would be beneficial here given the blankness of these regions, but it is no worse than the American rule. The key difference is that the slightly greater party generosity in settlement under the British rule (visible in Figures \ref{fig:offers_american} and \ref{fig:offers_british}) leads to more settlement. It is not obvious that this should be the result. While a party that expects to lose more likely than not should be more generous, a party that expects to win should be less generous. (The analysis for now ignores that parties may spend more when the British rule applies, an issue to which we will return.) The increased settlement naturally decreases expenditures in the British rule, and it also modestly decreases false negatives and false positives. This initial face-off might qualify as a narrow win for the British, but, like the Battle of Bunker Hill, it might yet give some encouragement to the American side. 

\subsection{Costs and fee-shifting multipliers}

To develop a more complete picture of how fee-shifting intensity may affect case disposition and thus accuracy and expenditures, we can vary the costs level and introduce a wider range of fee-shifting levels. Recall that in the baseline $c_{file}=c_{answer}=c_{trial}=0.15$, so if a case goes to trial, each party spends 0.3, or 30\% of the amount at stake. Yet there may be some cases in which costs, broadly conceived, may be much lower relative to stakes and others in which costs are higher. Thus, in Figure \ref{baseline}, the baseline costs levels are multiplied by each element of $\{\frac{1}{4}, \frac{1}{2}, 1, 2, 4\}$, and five fee shifting multipliers, ranging from 0 (representing the American rule) to 2 (where the loser pays twice the winner's fees) are included. Although multiple fee shifting certainly would be unusual, Polinsky and Rubinfeld (1996) \cite{polinskyrubinfeld1996} recognize that it is unclear what the optimal multiple is. After all, without a multiple, a party with a 75\% chance of winning would expect on average to bear half the per-party costs (one quarter of the parties' combined costs). Because costs are exogenous in the model, the fee shifting multiple can be viewed more generally as a range of penalties that the loser must pay to the winner.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Dispositions with baseline parameters, varying costs and fee shifting multipliers}
\label{fig:disposition_baseline}
\end{figure}

The middle row of Figure \ref{baseline} confirms, interpolates, and extrapolates what we determined above. The stacked bars represent the disposition of cases, with each group of stacked bars reflecting the results of one simulation and different dispositions coded with different patterns. The amount of fee shifting has relatively minimal effects on the number of cases that the plaintiff does not bring or the defendant does not answer. But fee shifting does affect settlement, increasing it at least up to a multiplier of 1. For multipliers above this level, some of the settled cases do not settle and instead become cases in which the plaintiff or the defendant gives up before trial. There is less pressure to settle if there is a good chance that the other party will quit rather than fight. Finally, the rate of trial is lower, the greater the amount of fee-shifting. 

Dari-Mattiacci and Saraceno (2020) note that the "common wisdom" is that the English rule discourages settlement. This observation dates to early papers on fee-shifting, such as Shavell (1982). The intuition is that the cases that tend to go to trial will be those in which the parties are mutually optimistic, and if the parties are sufficiently mutually optimistic, each will expect to benefit from fee-shifting, so fee-shifting makes settlement less likely. A problem with this logic is that a rational Bayesian should recognize that if trial occurs, that will be the result of mutual optimism. Dari-Mattiacci and Saraceno counter the common wisdom, in a model in which damages are uncertain, by deriving a result "that the rate of litigation [meaning trial] is independent of the fee-shifting rule." (p. 14) The data here further undermines the common wisdom by demonstrating that, at least under some parameters, settlement will become more common and trial will become less common with greater amounts of fee-shifting. This conclusion reflects not only settlement dynamics but also decisions whether to file and answer, which Dari-Mattiacci and Saraceno consider informally (p. 13). 

The result that trial levels fall with fee-shifting survives an examination of the other rows of the chart, which consider other costs levels. Moreover, the effect is even more stark if one reads the chart by moving not just to the right to observe the effect of a higher level of fee shifting, but simultaneously also up to observe the effect of a higher level of costs. Making a comparison in the style of a chess bishop may be justified because when fee shifting is greater, parties may spend more on litigation. Katz (1987) \cite{katz}, for example, estimates that changing from the American rule to the British rule might increase per case expenditures in tried cases by as much as 125\%. Thus, one might assess the effect of such a change by comparing the results associated with a 0 fee shifting multiplier and a costs multiplier of 1 with those for multipliers of 1 and 2, respectively. If fee shifting in fact makes litigation more expensive, the model here suggests that it will also make trial considerably less common.

When comparing across or diagonally, even more apparent than the change in the trial rate is the change in the rates at which suits are filed and contested.  With the lowest cost cases, suit is always filed and contested, and no one quits after settlement failure. In these cases, higher fee shifting multiples generally lead to more settlement, although there is little difference among the middle range of multipliers. With the highest costs cases, where the combined cost of trial exceeds the stakes, cases are rarely brought, and those brought are rarely defended. The remainder are mostly settled to avoid the trial costs, and if not settled, abandoned, with very few cases going to trial. One should thus expect very few contested cases to have such high costs relative to stakes. Such an absence may not mean that the litigation system always succeeds at keeping costs to a reasonable percentage of stakes, but instead that such cases are rarely litigated. This need not necessarily signify a failure of the legal system; note that about half of the uncontested cases are nonsuits and half are defaults, and many of these will end in the correct outcome with minimal if any litigation expenditures. Indeed, one might tentatively venture that error costs and litigation costs are paradoxically lower when the cost of the legal system is higher. 

On these parameters, though, that inference would be wrong. Figure \ref{fig:accexp_baseline} illustrates false negative and false positive inaccuracy, as well as average expenditures on litigation, including in the denominator all potential cases, not just those actively litigated. As costs rise, all of these lines generally rise with them. With the highest costs, false negatives are very high relative to false positives, especially with fee shifting. The timing of litigation affords the defendant an informational advantage; there are some suits that the defendant would drop that are never brought by the plaintiff. Enough of the cases are still litigated that expenditures amount to around 35\% of the stakes with the ordinary British rule. Still, this might be less than one would expect, only around three times greater than the level of total expenditures that occurs when costs are $\frac{1}{16}$ as large. The parties' greater hesitance to fight partially but incompletely offsets the increased relative cost of litigation.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Inaccuracy and expenditures with baseline parameters}
\label{fig:accexp_baseline}
\end{figure}

Within each graph within Figure \ref{fig:accexp_baseline}, the error costs and expenditure lines are relatively, though not perfectly, flat. This may seem at odds with another observation of Dari-Mattiacci and Saraceno, that fee-shifting better promotes accuracy in lower-cost litigation systems, perhaps explaining the pattern of different rules on opposite sides of the pond. The level of costs affects the level of errors, but increasing cost does not much weaken the case for fee-shifting. A close observation provides at most limited support for their claim. Error costs fall ever so slightly at the baseline costs level. (Total expenditures, a variable that they do not consider, also fall slightly.) 

\subsection{Risk aversion}

A computational model also can easily consider the effects of risk aversion. Utility with risk aversion is modeled as a function of wealth, $U=-e^{-\alpha W}$, and the values of $\alpha$ used to model risk aversion in these simulations are 1, 2, and 4. Recall that each party's initial wealth is set to 10.0, and stakes are 1.0. The shape of the risk aversion curves, with the x axis depicting wealth on the interval $[9, 11]$,  are displayed in Figure \ref{fig:riskaversion}. The y-axis utility values are omitted, because the utility values can be (and are) linearly transformed without affecting the equilibrium. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.40, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Levels of risk aversion}
\label{fig:riskaversion}
\end{figure}

\subsubsection{Shared risk preferences}

Figure \ref{fig:disposition_riskaversion} confirms that trial becomes considerably more rare when the parties are risk averse, especially if risk aversion is pronounced. Anticipating the increased likelihood of achieving a settlement, parties are more likely to contest claims. In the middle row, for example, as risk aversion becomes greater, the proportion of cases in which the plaintiff does not file or the defendant does not answer falls. The effect is greater when fee shifting is absent. With moderate or high risk aversion and no fee shifting, litigation is always contested at the baseline costs level, and a very high percentage of cases settle. Introduction of fee shifting, however, greatly reduces the chance of settlement success. Risk aversion exacerbates the downside risk of fee shifting, and when settlement fails, one party or the other frequently quits rather than face trial. Still, the relationships are quite complex. In the rightmost panel of the middle row, for example, the proportion of cases resulting in settlement initially falls but then rises with increased settlement. When both parties are risk averse, each player seeks to avoid trial but also recognizes that the other player is also risk averse, making trial unlikely. At the highest costs levels, however, risk aversion makes trial and even settlement very unlikely. With high risk aversion and a costs multiplier of 4, fee shifting means that the merits cease to differentiate outcomes, as either the plaintiff never files or the defendant never answers.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Dispositions varying risk aversion}
\label{fig:disposition_riskaversion}
\end{figure}

Sufficiently high risk aversion makes the litigation game similar to the famous game theory game of chicken (or, for biologists, hawk-dove). In contrast to the classic game of chicken, however, the parties are not identically situated, and which party has the more credible threat to go to trial may vary based on their signals, the costs levels, and the rules. Given these complex dynamics, it is not surprising that the effects on inaccuracy and expenditures are more complex as well, especially with high levels of risk aversion, high levels of costs, and high degrees of fee shifting. The bottom three rows of Figure \ref{fig:accexp_riskaversion} suggest that mild risk aversion has relatively small effects. Overall, there is less inaccuracy and there are lower expenditures with mild risk aversion than with risk neutrality, though of course the false negative inaccuracy and false positive inaccuracy may have a greater effect on welfare. With moderate risk aversion and cost multipliers of 0.5 or 1, the benefits of fee shifting are accentuated. But with the highest levels of risk aversion, the picture becomes more complex at those costs multipliers, with moderate fee shifting multipliers performing considerably better than higher multipliers. At the highest costs level, the two inaccuracy measures sharply diverge in some places, as the party too cowardly to contest litigation suffers.  All in all, the data suggests that with mutual mild risk aversion, ordinary fee shifting will generally produce benefits, but the dynamics are more complex and predictions more uncertain with high ratios of costs to stakes.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Inaccuracy and expenditures with risk aversion}
\label{fig:accexp_riskaversion}
\end{figure}

\subsubsection{Asymmetric risk preferences}

The above analysis assumed that both parties had the same level of risk aversion. What happens if one party is more risk averse than the other? Predictably, that has significant effects on willingness to contest litigation. Figure \ref{fig:disposition_riskaversionasymmetry} illustrates this. When the plaintiff is risk averse and the defendant is risk neutral, or the plaintiff is moderately risk averse and the defendant is only mildly risk averse, there are many cases in which the plaintiff does not file, and very few in which the defendant does not answer. The reverse pattern obtains when the defendant is more risk averse. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Disposition of cases with asymmetric risk aversion}
\label{fig:disposition_riskaversionasymmetry}
\end{figure}

The result is a divergence between the false negative inaccuracy and false positive inaccuracy rates. When the plaintiff is less likely to file, there are high risks of false negatives, and the reverse is true when the defendant is less likely to file. As shown in Figure \ref{fig:accexp_riskaversionasymmetry}, these effects are relatively small when costs are relatively low and neither party is more than mildly risk averse. The divergence becomes greater with higher costs and greater levels of risk aversion. It also generally becomes greater within the individual graph panels when the fee shifting multipliers increase. The intuition is that fee shifting increases the stakes, and it thus exacerbates the effects of asymmetric risk aversion. This is not true in all cases. Consider, for example, the row where the costs multiplier is 0.5 and both parties exhibit at least some risk aversion. Still, the general point is that risk aversion is not a healthy trait in a poker player. A striking pattern in Figure \ref{fig:disposition_riskaversionasymmetry} is that when parties quit after settlement failure with high levels of fee shifting, the quitting litigant is more likely to be the \textit{less} risk averse party. Contesting a litigation when one has no intention of going to trial is a form of bluff, and the less risk averse party is in a better position to bluff. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Inaccuracy and expenditures with asymmetric risk aversion}
\label{fig:accexp_riskaversionasymmetry}
\end{figure}

\subsection{Informational endowments}

We will now return to our assumption of risk neutrality, though the Supplemental Materials contain a version of every simulation not focusing on risk run under conditions of mild risk aversion. Perhaps as important as risk aversion is the degree to which players are able to ascertain the strength of the case. Recall that $\sigma_{LS}^P$ and $\sigma_{LS}^D$ represent the standard deviation of the normal distribution used to obfuscate the signal of liability strength received by the plaintiff and defendant, respectively. In these simulations, the noise affecting the court, $\sigma_{LS}^C$ is set to the noise of the party with stronger information. The baseline value of these variables is 0.2. Meanwhile, $\sigma_{LS}$, with a baseline value of 0.35, governs the relationship between true liability status and case strength, with lower values leading to a tighter connection. Figure \ref{fig:liabilitysignalsdefault} illustrates the baseline values, and the Supplemental Materials include diagrams illustrating the other signal values used in this section.

\subsubsection{Player noise level}

If the litigants both have better information, they are more likely to be able to avoid litigation, either through settlement or because one party does not contest the litigation. This is illustrated in Figures \ref{fig:dispositions_playernoise} and \ref{fig:accexp_playernoise}. With the lowest levels of noise (that is, the best information) and the lowest costs, cases are always filed, because a settlement is likely, but with higher costs, even at half of our baseline, nuisance suits may not be worth the cost of filing for the plaintiff, and nuisance defenses may not be worth the cost for the defendant. As a result, total error costs and expenditures are virtually unchanged in the lower three rows of the left column, with the cost savings of cheaper litigation entirely erased by greater pursuit of litigation. At the highest cost levels, an asymmetry develops in favor of the defendant, once again because on occasion the plaintiff decides not to bring a suit that the defendant would not have contested. Meanwhile, fee shifting plays an important role when player information is strong, though its overall effect is limited, because the vast majority of potential cases are not contested at all. For costs in the middle range, there is a decline in trial as a result of fee-shifting, albeit from already relatively low levels. If a case appears to be in the middle of the probability spectrum, without fee-shifting it might be worth it to pursue the case to trial, but with fee shifting, if settlement fails, at least one player is likely to make a Bayesian inference that victory is unlikely and give up. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on player noise levels}
		\label{fig:dispositions_playernoise}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on player noise levels}
		\label{fig:accexp_playernoise}
    \end{minipage}
\end{figure}

With high noise and bad information, the picture is quite different. Litigation becomes a crapshoot, and cases are likely to go to trial when costs are relatively low. When costs are higher, a wide range of outcomes are possible. With the highest level of cost and the highest level of noise, the plaintiff takes advantage by always filing. The defendant then realizes that if the defendant answers, both will still have sufficient incentive to negotiate aggressively that trial is a real possibility, a disaster resulting in each party paying more than the amount at stake altogether. This example is a special, extreme case of a negative expected value suit that can be rational for a plaintiff to bring. Slight changes in assumptions can lead to significant changes in equilibria; for example, in the equivalent to the top-right cell with risk aversion (not shown but available in the Supplemental Materials), the plaintiff never files. We cannot rule out the possibility that there are multiple equilibria here, as in the game of chicken. Overall, with high noise, the effect of fee shifting is relatively low. At the limit, if neither party has any information, then the expected value of fee shifting for a risk neutral party is 0.  

\subsubsection{Information quality asymmetry}

Figures \ref{fig:dispositions_playernoise} and \ref{fig:accexp_playernoise} assume that the players have equally high-quality information, whatever the noise level might be. In this section, we consider the possibility that one party has higher quality information. In Figures \ref{fig:dispositions_playernoise_asymmetry} and \ref{fig:accexp_playernoise_asymmetry}, the middle column reflects a situation in which the plaintiff experiences half as much noise ($\sigma_{LS}^P=0.1$) while the defendant experiences twice as much ($\sigma_{LS}^D=0.4$), and that is reversed in the column further to the right. This change makes our model quite close to conventional one-sided asymmetric information models, where one party knows the precise probability of liability and the other party knows only the distribution. Placing aside the row with very low costs, fee shifting in such a situation tends to reduce the incidence of settlement, as most models suggest. The story, however, is more complex than the typical signaling model (in which the party with the information makes an offer) or screening model (in which the party who lacks the information makes the offer), and the outcome is neither a pure pooling or pure separating equilibrium. Rather, as in most of the models here, the parties are sometimes able to enter into settlements, but often fail to reach agreement. 

Settlement becomes quite rare with medium to high costs and a fee shifting multiplier of 1 or greater. If the party with high-quality information knows that it has a strong case, then it has little reason to make concessions in settlement, because it is likely to benefit from fee shifting. Thus, the party with high-quality information will make concessions only if its case is relatively weak. The party with low-quality information thus faces a lemons problem: If the opponent makes sufficient concessions to allow a reasonable settlement, it is likely the case that the opponent knew its case was weak, in which case settlement was inadvisable for the party with low-quality information. Settlement thus becomes rare or nonexistent. Meanwhile, the party with high-quality information may abandon the litigation assuming settlement fails if the information indicates that its case is actually weak. The party with low-quality information also has some reason to quit. After all, if the party with high-quality information continues to trial despite a high level of fee shifting, that probably means that the party with high-quality information knows that it has a strong case. 

Thus, the party with high-quality information will continue to trial if it has a reasonably favorable signal, and the party with low-quality information will continue to trial only if it has a very favorable signal. The result is among cases that are tried, the party with better information wins a high percentage of the time. This is, of course, not inconsistent with the famous result of Priest and Klein (1984) \cite{priestklein}. They showed that the plaintiff would win half of all cases only in a limit equilibrium, as both parties' information became sufficiently strong. The analysis here suggests that with high information quality asymmetry, plaintiff win rates may be considerably higher than 50\%, if the plaintiff has higher-quality information, or considerably lower than 50\%, in the reverse situation. Anticipating these bargaining dynamics, the party with low-quality information becomes less likely to contest suit as the fee shifting multiplier increases, at least when costs are relatively high, and the party with high-quality information will almost always contest, unless its information is especially bad, because of the chance that the opponent will quit.

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on information quality asymmetry}
		\label{fig:dispositions_playernoise_asymmetry}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on information quality asymmetry}
		\label{fig:accexp_playernoise_asymmetry}
    \end{minipage}
\end{figure}

The informational advantage produces small reductions in the danger that the party that possesses it will suffer the adverse effects of inaccuracy, while imposing such adverse effects on the other party. For example, in the column in which the plaintiff has better information, false negative inaccuracy, which occurs when a meritorious plaintiff receives too little on net, is slightly lower than in the baseline simulation.  But false positive inaccuracy is much worse. Fee shifting, meanwhile, modestly amplifies these effects, reducing the danger of inaccuracy for the party with better information but increasing inaccuracy for the other party. Meanwhile, the effect of fee shifting on expenditures is indeterminate, falling in some panels while rising in others. The attractiveness of fee shifting when information is highly asymmetric will thus depend on which type of inaccuracy looms larger in the social loss function. If the two forms of inaccuracy are given equal weight and the the effect of expenditures is indeterminate or small, the American rule is likely to be superior with highly asymmetric risk aversion.

\subsubsection{Quality of the legal system}

So far, this section has focused on variations to the noise that obfuscates the liability quality when observed by a party as a liability signal. We may also vary $\sigma_{LS}$, the noise level that determines the liability signal given that a case is one in which the defendant is or is not truly liable. This can be seen as a measure of the quality of the legal system. (Varying $\sigma_{LS}^C$, the noise obfuscating the court's determination, might have a similar effect, but we simply assume that the court's information is as good as the better informed party's. Altering this might usefully be varied to assess the effects of judicial bias if the parties can predict the court's bias, but we leave this for future work.)  Figure \ref{fig:accexp_qualitylegalsystem} provides a visualization of the effect of effect choosing a lower or higher value for case strength noise, using the baseline level of costs. The full diagram, which is available in the Supplemental Materials, shows similar effects. The primary effect of increasing the case strength noise is to increase inaccuracy and expenditures, and the reverse is true for decreasing the case strength noise. This is as one would expect. If cases in which the defendant is truly liable are often cases in which the defendant is likely to win, the legal system will not be as successful in its aims. But the data suggest that such a change does not have major consequences for an analysis of the relative effect of changing the fee shifting multiplier. This provides some reassurance that the admittedly arbitrary choice of a case strength noise level is not likely to be driving results.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.50, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Inaccuracy and expenditures varying case strength noise}
\label{fig:accexp_qualitylegalsystem}
\end{figure}

\subsection{Costs structure}

In each section, we have considered the possibility of different ratios of costs to the stakes of the case. Yet in our examples, the plaintiff's cost of filing has equaled the defendant's cost of answering, and the trial cost has been that same amount for each party. In this section, we consider the possibility that the parties might bear different costs of litigation, or that the timing of costs might be weighted either toward the initiation of the case or toward trial.

\subsubsection{Relative costs}

A party might bear higher costs than its adversary because it chooses a pricier lawyer. The choice of attorney, which would affect likelihood of winning at trial, is beyond our scope here. But other parties also might bear different levels of costs for reasons outside their control. For example, the burden of discovery might fall more heavily on one party or the other. In Figures \ref{fig:dispositions_costsasymmetry} and \ref{fig:accexp_costsasymmetry}, we consider, in addition to the baseline scenario, a scenario in which the plaintiff's costs, both for filing and for trial, are half what they otherwise would be, and one in which the plaintiff's costs are twice what they ordinarily would be. In both scenarios, the defendant's costs are constant. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition with asymmetric costs}
		\label{fig:dispositions_costsasymmetry}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures with asymmetric costs}
		\label{fig:accexp_costsasymmetry}
    \end{minipage}
\end{figure}

As one would expect, facing higher costs than one's opponent leads one to face a greater danger of inaccuracy. In the left column, false positives (adversely affecting the defendant) are generally greater in magnitude than false negatives, given the plaintiff's lower costs. And in the right column, the plaintiff's higher costs generally translate into a greater magnitude of false negatives than false positives. The effects start at the pleading stages. A plaintiff is more likely not to file a lawsuit at any level of costs than in the condition in which the plaintiff has lower costs or the parties have the same costs. The effect on the defendant is more muted. Because the plaintiff does not file relatively often when the plaintiff faces high costs, when the plaintiff does file, that provides a credible signal to the defendant that the plaintiff has relatively favorable information. Meanwhile, greater degrees of fee shifting tend to mitigate the advantage of asymmetric costs. The false positives and false negatives become closer together in general to the right of the minigraphs in Figure \ref{fig:accexp_costsasymmetry}. With fee shifting of at least 1, the party that bears the cost is not necessarily the party that spends the money. But the sum of false negative and false positive costs may not decline.  Meanwhile, with asymmetric costs, expenditures tend to decline with higher fee shifting levels, but this is not true in all panels.

\subsubsection{Time allocation of costs}

Settlement bargaining dynamics depend considerably on when costs are incurred. Figures \ref{fig:dispositions_timing} and \ref{fig:accexp_timing} hold constant the total costs that the parties will bear if a case goes to trial, but vary the proportion of those costs that are borne at the beginning or the end. In the leftmost column, there is no cost to filing or answering, so of course the parties always file and answer. The dynamics are akin to models that consider only settlement and ignore the prior decisions of whether to file and defend. Especially with moderate to high costs, a party often gives up if settlement fails. Trial is relatively more expensive (because total costs are fixed), and so a party that thinks it has a weak case will likely not proceed to trial. Meanwhile, the column furthest on the right assumes that all of the costs are borne at filing, and trial is free. This extreme seems unlikely, but there may be cases where the amount of work that precedes settlement negotiation is great, and the expense of trial is low in relative terms. Unsurprisingly, in this circumstance, it is common for parties not to contest litigation, and fee shifting magnifies this effect when costs are relatively low. Once a suit is filed, it is pursued to trial absent settlement, which rarely succeeds. Overall, fee shifting again reduces the incidence of trial.

The net effects on error costs and total expenditures are relatively small. In the middle baseline column, unless costs are very high, total expenditures tend to fall modestly with greater amounts of fee shifting, and the same is true in the other four columns. Whether the moment of truth occurs before or after settlement negotiations, increased fee shifting, especially double fee shifting, decreases trial rates. Accuracy effects are more equivocal, and the false positive and false negative lines are flatter than they are in many of the interventions. The greater the proportion of costs at the beginning, the greater the tendency of false positives and false negatives to be minimized in the middle of the fee shifting spectrum, with the British rule. But there are exceptions, especially at higher costs levels, where the differential timing of plaintiff and defendant decisions plays a larger role. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on timing of costs}
		\label{fig:dispositions_timing}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on timing of costs}
		\label{fig:accexp_timing}
    \end{minipage}
\end{figure}

\subsection{Game structure}

In all of the simulations so far, the game tree has remained the same. This section considers three possible changes to the game structure. It first considers case in which damages are at issue instead of liability. That provides an opportunity to examine the fee shifting mechanism embodied by Federal Rule of Civil Procedure 68, which has more relevance to damages cases, as well as fee shifting rules in liability cases that resemble Rule 11 in imposing fees only when the margin of victory is high. Finally, we consider the effects of eliminating the right to quit if settlement fails, a variation of an intervention that some have suggested.

\subsubsection{Damages cases}

When damages are at issue, the model assumes that the plaintiff is always liable and that there is some true level of damages of which the parties receive a signal. The true level of damages is assumed to be uniformly distributed across 10 values, and the plaintiff's and defendant's signals of true damages quality are the same as their signals of true liability quality, $\sigma_{DS}^P=\sigma_{DS}^D=0.2$. Figure \ref{fig:damagessignals} provides the damages analogue to Figure \ref{fig:liabilitysignalsdefault}.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.4, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Damages signals given true damages strength}
\label{fig:damagessignals}
\end{figure}

Because the defendant is always liable, fees are always shifted against the defendant if the case goes to trial. The result, illustrated in Figures \ref{fig:dispositions_issue} and \ref{fig:accexp_issue} is that fee shifting greatly decreases the defendant's willingness to go to trial. With very low costs, fee shifting results in more settlement, but in all but the lowest row, fee shifting substantially increases the proportion of cases in which the defendant decides not to contest liability, thus paying the full damages demanded by the plaintiff. The result is that false positives greatly increase, considerably more than false negatives decrease. The analysis suggests the obvious conclusion that courts must be careful in determining when fee shifting applies. Applying fee shifting whenever the plaintiff prevails on the issue of liability will not make sense if the defendant has conceded liability and contests damages. Indeed, courts applying the British rule often explicitly recognize that the party entitled to attorneys' fees is the party that prevailed on the significant issues in a case. \textit{See, e.g.}, Trytek v. Gale Indus., 3 So. 3d 1194 (Fla. 2009). This highlights, however, a need for models that consider the possibility that liability \textit{and} damages are at issue. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on issue in case}
		\label{fig:dispositions_issue}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on issue in case}
		\label{fig:accexp_issue}
    \end{minipage}
\end{figure}

\subsubsection{Fee-shifting rules}

In cases in which damages are at issue, Federal Rule of Civil Procedure 68 or mechanisms similar to it may be useful. Under Rule 68, if a defendant makes a settlement offer to a plaintiff, and the defendant is found liable but the damages are less than the plaintiff was ordered, the plaintiff must pay the defendant's costs. Under \textit{Delta Air Lines, Inc. v. August}, 450 U.S. 346 (1981), the plaintiff is not required to pay the defendant's costs when the defendant wins the lawsuit. If the plaintiff were required to do so, Rule 68 would amount to a simple one-way cost-shifting rule, because the defendant would always offer a nominal settlement, such as one dollar, and then seek shifting if the defendant prevailed. Thus, Figures \ref{fig:dispositions_damagesrule} and \ref{fig:accexp_damagesrule} reflect assumptions that the defendant is always truly liable and is found liable. The amount that the plaintiff is required to pay is equal to the defendant's initial fees times the fee multiplier, but only when the rule is triggered.  

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on fee-shifting rule}
		\label{fig:dispositions_damagesrule}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on fee-shifting rule}
		\label{fig:accexp_damagesrule}
    \end{minipage}
\end{figure}

The figures also reflects simulations employing a variation on Rule 68, for which we use the label "Reverse 68." Under this Rule, the British rule is the default, so the plaintiff may be entitled to fee shifting, but if Rule 68 is triggered, the plaintiff suffers a double whammy. Not only does the plaintiff not receive the fee shifting to which it ordinarily would be entitled, but in fact must pay the defendant for having rejected its offer. Arguably, Reverse 68 is closer to how Rule 68 works in practice, because the prevailing party ordinarily is entitled to costs under Rule 67, and Rule 68 sometimes changes that entitlement. This has virtually no effect in practice, however, because costs are generally small relative to attorneys' fees, which are not allowed under Rule 68. We thus use the phrase "Rule 68" to describe a hypothetical version of Rule 68 that applies to all costs and fees, and the phrase "Reverse 68" to describe the effect of that rule if the United States hypothetically simultaneously changed to the British rule default.

Different fee-shifting rules also may be used when the issue is liability rather than damages. We simulated fee-shifting based on the margin of victory, as discussed in Bebchuk and Chang (1996) \cite{bebchukchang}. Specifically, we considered the possibility that the court might impose fee shifting only if the court's signal of liability were at least equal to 0.80. The results (omitted here, but available in the Supplemental Materials) show only small differences in dispositions and costs from baseline. Further work might examine a variety of different possible thresholds at which to apply margin-of-victory fee shifting.

\subsubsection{Quitting rules}

Finally, we consider the effect of removing the option that players have to quit after settlement failure. It is  useful in part because one can imagine a proposal under which parties are allowed to settle but not to quit. The intuition for such a proposal is that quitting allows a party to evade the fee shifting rule, escaping the need to pay for the other party's expenses incurred before trial. More importantly, however, this exercise is useful to facilitate assessment of theories, such as Huang (2004) \cite{huang} and Hubbard (2016) \cite{hubbard}, that highlight the importance of this option on settlement dynamics. We can assess whether optionality is more or less important with fee shifting.

Figures \ref{fig:dispositions_quit} and \ref{fig:accexp_quit} show that, at least with moderate to high costs, the rule barring settlement is counterproductive in the absence of fee shifting. The rule leads to more contested litigation. Each side recognizes that settlement is the only alternative to trial. Thus, a party that might not settle ordinarily, confident that the other side would abandon litigation, will be more inclined to settle, and thus a party with a slightly weak case will be more inclined to contest in the first place. Relative to a world in which those parties do not contest litigation, this is more expensive, and so litigation is more expensive, with little benefit in terms of false positives and negatives. When fee-shifting exists, however, the error costs and expenditures in the right column are fairly close to those in the left column. That does not create a strong argument in favor of instituting such a rule. Indeed, it illustrates that even though fee shifting can lead to bluffing followed sometimes by quitting, removing the ability to bluff would not significantly alter outcomes. The more general lesson is that litigation optionality, so critical to assessing incentives under the American rule, may matter less under the British. This is so even though parties are more likely to quit to avoid trial under the British rule, especially with multiple fee shifting, than under the American rule. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % first figure itself
        \caption{Disposition based on permissibility of quitting}
		\label{fig:dispositions_quit}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.98\textwidth, scale=0.70, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf} % second figure itself
        \caption{Errors and expenditures based on permissibility of quitting}
		\label{fig:accexp_quit}
    \end{minipage}
\end{figure}

\section{Analysis} \label{Robustness analysis}

This article's methodology has made it possible to generate exact equilibria for a wide variety of game permutations, 1,250 in all. But this leaves two questions about robustness. First, are the results dependent on the happenstance of stumbling upon some equilibria rather than others? Second, if multiple equilibria do exist and the parties play different equilibria, is that likely to significantly affect the results? And third, are the results dependent on the variables left fixed across simulations, namely the number of liability (or damages) strength values, the number of signals, and the number of offers? We address these issues in turn.

\subsection{Multiple equilibria}

The von Stengel, van den Elzen, and Talman (2002) algorithm is guaranteed to furnish a single exact equilibrium given any arbitrary initialization of the parties' information sets to fully mixed strategies. It does not provide a means of generating all of the perfect Nash equilibria, in contrast to the Lemke-Howson algorithm, which generates all Nash equilibria but is many orders of magnitude too slow for this problem. This raises the question whether the equilibria identified here are representative of the broader class of equilibria for each game type. We can address this by randomizing the parties' initial information sets to determine whether that generates multiple equilibria and, if so, how much variation there is among these multiple equilibria.

We performed this for the baseline simulation, both with and without fee shifting, by attempting to generate up to 50 equilibria for each. This produced 29 equilibria for the American rule, because 21 of the equilibria were repeats, and 9 for the British rule. We cannot from this exercise determine how many equilibria exist. In principle, these equilibria could be the entire populations or they could be a small sample. Figures \ref{fig:baseline_multieq_american} and \ref{fig:baseline_multieq_british} thus reports the coefficient of variation (the standard deviation divided by the mean) for various outcome variables among the American and British rule equilibria, respectively. The results are relatively reassuring. There is some variation with the American rule, particularly in the answer and offer decisions, but this results in only very small variation for our primary outcome variables of interest, error costs and expenditures. (The "Settles" variable is omitted; there were no settlements in all but one equilibria, and in that equilibria, 10.7\% of cases settled.) The results for the British rule are even more reassuring. The only outcome variable with a nonzero coefficient of variation was the plaintiff offer, at 0.03; this variation was insufficient to actually change whether any cases settled. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.5, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Coefficient of variation for 29 American rule equilibria}
\label{fig:baseline_multieq_american}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
		\includegraphics[scale=0.5, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Coefficient of variation for 9 British rule equilibria}
		\label{fig:baseline_multieq_british}
    \end{minipage}
\end{figure}

\subsection{Off-equilibrium play}

Chicken highlights a central concern about multiple equilibria, that if they exist, the parties might not coordinate on any one equilibrium. The only pure Nash strategies in chicken are those in which one party swerves and the other does not. Either way, no one dies. But if each player believes that they are coordinating on the equilibrium in which the other swerves, then both die. This outcome is also possible, of course, if they coordinate on the mixed strategy, in which each has a high probability of swerving, but is far more likely if there is a potential failure to coordinate on pure strategies. In the context of litigation, if the plaintiff believes that the equilibrium is one in which the plaintiff drives a hard bargain and the defendant thinks that the equilibrium is one in which the defendant drives a hard bargain, then they may end up with a nonequilibrium settlement failure that would not occur if both parties were coordinated.

Given the low coefficient of variation for the baseline scenarios, the noncoordination problem appears insignificant, but that does not rule out the possibility that off-equilibrium play could be considerably different from equilibrium play in other scenarios.  It was infeasible to generate a large number of equilibria for each of the 1,250 scenarios to assess the implications of coordination failure, given available computational resources. As a substitute, we generated up to 50 equilibria per scenario on a smaller game tree size, where $n_{LS}=n_{LS}^P=n_{LS}^D=n_{\mathcal{o}}=5$. For each equilibrium attempt, we initialized the mixed strategies at random in a way that allowed for the possibility that one action might have a much higher probability than others, in the hope of creating highly diverse starting points for the algorithm. For efficiency, we then attempted to find an equilibrium using floating point arithmetic. As noted above, that is not guaranteed to succeed because of numerical stability issues, so whenever it failed, we switched to seeking an equilibrium using exact arithmetic. We then collected all the unique equilibria produced. 

We then compared outcomes in a correlated equilibrium with outcomes in an average equilibrium. A correlated equilibrium, developed by Aumann (1974), is one in which each party, observing some signal of which equilibrium to play, has the incentive to follow that signal on the assumption that the other party will as well. Any set of Nash equilibria can be combined to create a correlated equilibrium, because if one knows that one's opponent is playing a particular Nash equilibrium, by definition one will want to play the strategy corresponding to that equilibrium as well. The average equilibrium is calculated simply by averaging the parties' mixed strategies at each information set. For example, if in half of equilibria, plaintiff files 100\% of the time conditional on a signal and in the other half, plaintiff files 50\% of the time conditional on that signal, then in the average equilibrium, plaintiff files 75\% of the time. The average equilibrium will thus have support over at least as many pure strategies as any of the original equilibria strategies. 

For each of the 1,250 parameter sets, we created a correlated equilibrium strategy and an average equilibrium strategy and computed the probability or average value of game outcomes for each. We then calculated how correlated the variables were for a number of variables of interest. The result is illustrated in Figure \ref{fig:correlations_corrvsave}, which shows the correlation coefficient across the 1,250 values for each outcome variable. This suggests that lack of ability to coordinate on any single strategy does not dramatically change the story.  

\begin{figure}[h!]
\centering
\includegraphics[scale=0.5, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
\caption{Correlations in outcome variables between correlated and average equilibria}
\label{fig:correlations_corrvsave}
\end{figure}

\subsection{Game tree size}

The equilibria on the smaller game tree also can be compared directly to the equilibria on the original game tree. This provides a test of whether results are highly sensitive to the granularity of the strategies. The diagrams illustrating equilibrium results for both the smaller and original game tree are available in the Supplemental Materials. We will offer here a partial visual comparison. Figures \ref{fig:treesize_panel1}-\ref{fig:treesize_panel4} compare the large and small trees, with dispositions under risk neutrality on the left and dispositions under mild risk aversion on the right. The results highlight that tree size can matter for some parameters. Particularly for the 0.5 costs multiple, settlements are more common on the small tree, for example. This may be because it is easier to coordinate on a settlement when there are only a handful of settlement choices than when there are a larger number. This might suggest that settlement might be slightly more common if liability strengths, signals, and offers were doubled yet again from our baseline parameters, with other resulting adjustments such as a greater chance of suit. Yet the broad general patterns of how dispositions change with costs and with greater intensity of fee shifting remain. 

\begin{figure}
    \centering
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[scale=0.15, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Risk neutral, large tree}
		\label{fig:treesize_panel1}
    \end{minipage}\hfill
    \begin{minipage}{0.24\textwidth}
        \centering
		\includegraphics[scale=0.15, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Risk neutral, small tree}
		\label{fig:treesize_panel2}
    \end{minipage}
   \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[scale=0.15, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Risk averse, large tree}
		\label{fig:treesize_panel3}
    \end{minipage}\hfill
    \begin{minipage}{0.24\textwidth}
        \centering
		\includegraphics[scale=0.15, trim={0in 0in 0in 0in}, clip]{../Figures/gametree.pdf}
		\caption{Risk averse, small tree}
		\label{fig:treesize_panel4}
    \end{minipage}
\end{figure}

\section{Conclusion}

The model has provided some surprises, while confirming some standard findings of the literature. Even when two risk-neutral parties have relatively strong information, a great deal of strategic behavior can occur and thwart settlement in a perfect Bayesian Nash equilibrium. Settlement offers at equilibrium rarely rise linearly with parties' estimates of the stakes, but change abruptly between stinginess and generosity. Fee shifting has relatively little effect on the rate at which litigation is contested, even with asymmetric risk aversion, or with different levels of party information, at least unless the parties are significantly risk averse. Parties with greater risk aversion or lower-quality information suffered considerably more from litigation inaccuracy than their adversaries.  When litigation becomes more expensive, fewer cases are contested, but the greater per-case expense and gamesmanship in file/answer and quitting decisions generally worsens social welfare outcomes. At very high levels of costs, especially when costs are backloaded, litigation becomes akin to a game of chicken. One or both parties may be bluffing by filing or answering, settlement becomes rare, and inaccuracy is high. 

Perhaps the most decisive conclusion that can be drawn from the constellation of models explored in the paper is that litigation may play out quite differently with different costs levels. An advantage of using a common model in different scenarios is that we can be more comfortable attributing the difference to the changes in parameters than we would be if comparing the implications of pairs of models making multiple different assumptions. The analysis illustrates more clearly than is possible under other models the complex interactions among file/answer decisions, settlement offers, and quit options, as well as how these change depending on case stakes, the degree of fee shifting, risk aversion, and a number of other variables. The comparisons suggest that the long-term goal must be either to develop different rules for different case types or to develop alternative litigation rules that tend to maximize social welfare under a wide range of parameters. 

With respect to fee-shifting, the project sheds light on how the presence or degree of fee-shifting affects the incidence of trial and social welfare measures. The most sophisticated model addressing these questions to date is Dari-Mattiacci and Saraceno (2020), who incorporate two-sided asymmetric information and fee-shifting. They conclude that fee-shifting does not affect the settlement rate and that fee-shifting tends to produce greater accuracy when litigation costs are relatively low. As detailed above, the simulations here seem largely inconsistent with these conclusions. 

Dari-Mattiacci and Saraceno's model includes a number of restrictive assumptions. A single variable serves two entirely separate functions in the model, representing both the true merits of the case and the degree of information asymmetry, thus preventing these considerations from being considered separately. That variable is then constrained to an intermediate range of values. The parties share knowledge of that variable and thus have information only about how factors independent of the truth may influence the judge. The imposition of fee shifting depends on whether the party that wins itself presented strong evidence, ignoring the other party's case.  The parties are arguing not over liability but over how to divide a disputed asset. The plaintiff always files, and the defendant always contests. The measures of inaccuracy take into account fee shifting but ignore the costs that can contribute to false positives and false negatives, and the measure compares the expectation of outcomes with the true merits, an approach that works only with risk neutrality. 

These observations are not intended as criticism. These sacrifices were needed and worthwhile to ensure tractability in a mathematical model. By translating litigation games into extensive form and applying a game theoretic algorithm, this article has allowed for a far wider range of variables to be considered and has avoided some of these sacrifices. Still, there may be situations in which the Dari-Mattiacci and Saraceno model may provide the better analysis, particularly where both parties know the truth of the matter, but neither party knows the evidence that the other may be able to assemble to convince the judge to award it more of a disputed asset. Our approach, assuming that each party receives a signal of the merits, is more general, but the Dari-Mattiacci and Saraceno approach may better fit some litigation. Future papers could adapt the approach here to a litigation game with the structure of Dari-Mattiacci and Saraceno's or to litigation games with other features.

At least three forms of skepticism about the methodology are warranted. First, litigants may not be rational Bayesians who play equilibrium strategies. But, as the literature generally presumes, models assuming rationality may provide a first guess at how litigants behave, and economic forces may gradually push actors in any given legal context toward equilibrium strategies.  Moreover, though more complicated to model, two-sided asymmetric information seems like a more accurate description of most litigation than one-sided information, and a model that recognizes the possibility that litigants may not contest litigation or may quit after settlement failure illustrates dynamics that some models assume away. 

Second, models' usefulness may depend on parameter values, and the parameters here are not calibrated based on data, either statistics from actual litigation or on microfoundations of individual behavior. Indeed, the heterogeneity of results that obtain from this model's admittedly arbitrary parameter choices highlight both the futility of assuming that any calibration will fit all litigation but also that calibration may be useful for particular types of cases. Risk aversion, for example, has a profound effect on the results, and even casual observation suggests that the high trial rates observed with risk neutrality are less plausible than the rates observed with mild risk aversion. The model also could be modified to incorporate behavioral considerations like regret aversion, which, experimental evidence in Guthrie (1999) \cite{guthrie} suggests, affects litigant behavior.

Third, although the model offers more bells and whistles than its mathematical predecessors, many chimes are still missing, including learning and bargaining over time, as well as the role of lawyers and agency costs. Indeed, this is but a first step toward building models that can incorporate even more complex features of the litigation game. Because the game tree size may increase exponentially with additional features, other computational game theory approaches that seek approximate equilibria may be needed to make larger game models solvable. 

\printbibliography
\end{document}
